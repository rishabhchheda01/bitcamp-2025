{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\kheri\\\\Downloads\\\\Bitcamp\\\\bitcamp-2025\\\\Bitcamp25\\\\test-voice\\\\src\\\\FaceDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';\nimport * as tf from '@tensorflow/tfjs';\nimport '@tensorflow/tfjs-backend-webgl';\nimport '@tensorflow/tfjs-backend-wasm';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\n\n// Initialize TensorFlow with the appropriate backend\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst initializeTF = async () => {\n  // Try to use WebGL first for better performance, fallback to WASM\n  try {\n    await tf.setBackend('webgl');\n    console.log('Using WebGL backend for TensorFlow.js');\n  } catch (e) {\n    try {\n      await tf.setBackend('wasm');\n      console.log('Using WASM backend for TensorFlow.js');\n    } catch (e) {\n      console.error('Failed to initialize TensorFlow backend:', e);\n    }\n  }\n};\nconst FaceDetection = /*#__PURE__*/_s(/*#__PURE__*/forwardRef(_c = _s(({\n  onHeadMovement,\n  active = true,\n  showDebug = false\n}, ref) => {\n  _s();\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const streamRef = useRef(null);\n  const modelRef = useRef(null);\n  const requestRef = useRef(null);\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\n  const lastPositionRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const centerPointRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const calibrationRef = useRef(false);\n  const [faceDetected, setFaceDetected] = useState(false);\n\n  // Expose functions to parent component\n  useImperativeHandle(ref, () => ({\n    calibrate: () => {\n      calibrate();\n    },\n    isCalibrated: () => {\n      return calibrationRef.current;\n    },\n    isFaceDetected: () => {\n      return faceDetected;\n    }\n  }));\n\n  // Load face detection model\n  const loadModel = async () => {\n    try {\n      // Load the MediaPipe Facemesh package using the current API\n      modelRef.current = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, {\n        runtime: 'mediapipe',\n        refineLandmarks: false,\n        maxFaces: 1\n      });\n      setIsModelLoaded(true);\n      console.log('Face detection model loaded');\n    } catch (error) {\n      console.error('Failed to load face detection model:', error);\n    }\n  };\n\n  // Set up webcam streaming\n  const setupCamera = async () => {\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\n      return;\n    }\n    try {\n      // Get access to the webcam\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\n        video: {\n          width: 640,\n          height: 480,\n          facingMode: 'user'\n        }\n      });\n\n      // Set the video source\n      if (videoRef.current) {\n        videoRef.current.srcObject = streamRef.current;\n      }\n    } catch (error) {\n      console.error('Failed to access webcam:', error);\n    }\n  };\n  const calibrate = () => {\n    if (lastPositionRef.current) {\n      centerPointRef.current = {\n        ...lastPositionRef.current\n      };\n      calibrationRef.current = true;\n      console.log('Calibrated face position:', centerPointRef.current);\n    }\n  };\n\n  // Draw facial landmarks for debugging\n  const drawFacialLandmarks = (predictions, ctx) => {\n    if (!ctx || !predictions || predictions.length === 0) return;\n\n    // Clear the canvas\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n\n    // Draw each prediction\n    predictions.forEach(prediction => {\n      // Draw facial keypoints\n      if (prediction.keypoints) {\n        for (let i = 0; i < prediction.keypoints.length; i++) {\n          const keypoint = prediction.keypoints[i];\n\n          // Draw keypoint\n          ctx.beginPath();\n          ctx.arc(keypoint.x, keypoint.y, 1, 0, 2 * Math.PI);\n          ctx.fillStyle = 'aqua';\n          ctx.fill();\n        }\n      }\n\n      // Find nose point\n      const nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\n      if (nose) {\n        // Draw the nose point in a different color\n        ctx.beginPath();\n        ctx.arc(nose.x, nose.y, 5, 0, 2 * Math.PI);\n        ctx.fillStyle = 'green';\n        ctx.fill();\n\n        // Draw a line from the center calibration point to current nose position\n        if (calibrationRef.current) {\n          ctx.beginPath();\n          ctx.moveTo(centerPointRef.current.x, centerPointRef.current.y);\n          ctx.lineTo(nose.x, nose.y);\n          ctx.strokeStyle = 'white';\n          ctx.lineWidth = 2;\n          ctx.stroke();\n\n          // Draw the center calibration point\n          ctx.beginPath();\n          ctx.arc(centerPointRef.current.x, centerPointRef.current.y, 5, 0, 2 * Math.PI);\n          ctx.fillStyle = 'red';\n          ctx.fill();\n        }\n      }\n    });\n  };\n\n  // Detect faces and send head movement\n  const detectFaces = async () => {\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\n      requestRef.current = requestAnimationFrame(detectFaces);\n      return;\n    }\n    try {\n      // Get predictions using the updated API\n      const predictions = await modelRef.current.estimateFaces(videoRef.current, {\n        flipHorizontal: true\n      });\n\n      // Update face detected state\n      setFaceDetected(predictions.length > 0);\n\n      // Draw landmarks if debug is enabled\n      if (showDebug && canvasRef.current) {\n        const ctx = canvasRef.current.getContext('2d');\n        drawFacialLandmarks(predictions, ctx);\n      }\n      if (predictions.length > 0) {\n        // Get nose point (middle of the face)\n        const nose = predictions[0].keypoints.find(kp => kp.name === 'nose_tip');\n        if (nose) {\n          // Store current position\n          lastPositionRef.current = {\n            x: nose.x,\n            y: nose.y\n          };\n\n          // If we haven't calibrated yet, do it now\n          if (!calibrationRef.current) {\n            calibrate();\n            return;\n          }\n\n          // Calculate difference from center (calibrated position)\n          const deltaX = nose.x - centerPointRef.current.x;\n          const deltaY = nose.y - centerPointRef.current.y;\n\n          // Determine thresholds for movement (adjust these values as needed)\n          const thresholdX = 30;\n          const thresholdY = 30;\n\n          // Determine movement direction\n          let direction = null;\n\n          // Check horizontal movement (left/right)\n          if (deltaX < -thresholdX) {\n            direction = 'l'; // Left\n          } else if (deltaX > thresholdX) {\n            direction = 'r'; // Right\n          }\n          // Check vertical movement (up/down) - Y increases downward in image coordinates\n          else if (deltaY < -thresholdY) {\n            direction = 'u'; // Up\n          } else if (deltaY > thresholdY) {\n            direction = 'd'; // Down\n          }\n\n          // Call the callback with the detected direction\n          if (direction && onHeadMovement) {\n            onHeadMovement(direction);\n          }\n        }\n      }\n    } catch (error) {\n      console.error('Error during face detection:', error);\n    }\n\n    // Continue detection loop\n    requestRef.current = requestAnimationFrame(detectFaces);\n  };\n\n  // Initialize camera and model\n  useEffect(() => {\n    if (active) {\n      initializeTF().then(() => {\n        setupCamera().then(() => {\n          loadModel();\n        });\n      });\n    }\n    return () => {\n      // Clean up resources\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n        requestRef.current = null;\n      }\n      if (streamRef.current) {\n        const tracks = streamRef.current.getTracks();\n        tracks.forEach(track => track.stop());\n        streamRef.current = null;\n      }\n    };\n  }, [active]);\n\n  // Start detection when model is loaded\n  useEffect(() => {\n    if (isModelLoaded && active) {\n      detectFaces();\n    }\n    return () => {\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n      }\n    };\n  }, [isModelLoaded, active, showDebug]);\n\n  // Handle video loaded\n  const handleVideoLoaded = () => {\n    console.log('Video element is ready');\n\n    // Set canvas dimensions to match video\n    if (canvasRef.current && videoRef.current) {\n      canvasRef.current.width = videoRef.current.videoWidth;\n      canvasRef.current.height = videoRef.current.videoHeight;\n    }\n  };\n\n  // Reset calibration with a function that can be exposed if needed\n  const resetCalibration = () => {\n    calibrationRef.current = false;\n    console.log('Calibration reset');\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: `face-detection ${showDebug ? 'debug-mode' : ''}`,\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      width: \"320\",\n      height: \"240\",\n      autoPlay: true,\n      playsInline: true,\n      muted: true,\n      onLoadedData: handleVideoLoaded,\n      style: {\n        display: showDebug ? 'block' : 'none'\n      },\n      className: \"face-video\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 279,\n      columnNumber: 7\n    }, this), showDebug && /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"320\",\n      height: \"240\",\n      className: \"landmarks-canvas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 292,\n      columnNumber: 9\n    }, this), !isModelLoaded && active && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"loading-model\",\n      children: \"Loading face detection model...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 301,\n      columnNumber: 9\n    }, this), faceDetected && active && !showDebug && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"face-detection-status\",\n      children: [\"Face \", calibrationRef.current ? 'Tracked' : 'Detected']\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 305,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 278,\n    columnNumber: 5\n  }, this);\n}, \"qWFLgGl2VifbDxvDsfBbJhvelBw=\")), \"qWFLgGl2VifbDxvDsfBbJhvelBw=\");\n_c2 = FaceDetection;\nexport default FaceDetection;\nvar _c, _c2;\n$RefreshReg$(_c, \"FaceDetection$forwardRef\");\n$RefreshReg$(_c2, \"FaceDetection\");","map":{"version":3,"names":["React","useEffect","useRef","useState","useImperativeHandle","forwardRef","tf","faceLandmarksDetection","jsxDEV","_jsxDEV","initializeTF","setBackend","console","log","e","error","FaceDetection","_s","_c","onHeadMovement","active","showDebug","ref","videoRef","canvasRef","streamRef","modelRef","requestRef","isModelLoaded","setIsModelLoaded","lastPositionRef","x","y","centerPointRef","calibrationRef","faceDetected","setFaceDetected","calibrate","isCalibrated","current","isFaceDetected","loadModel","createDetector","SupportedModels","MediaPipeFaceMesh","runtime","refineLandmarks","maxFaces","setupCamera","navigator","mediaDevices","getUserMedia","video","width","height","facingMode","srcObject","drawFacialLandmarks","predictions","ctx","length","clearRect","canvas","forEach","prediction","keypoints","i","keypoint","beginPath","arc","Math","PI","fillStyle","fill","nose","find","kp","name","moveTo","lineTo","strokeStyle","lineWidth","stroke","detectFaces","readyState","requestAnimationFrame","estimateFaces","flipHorizontal","getContext","deltaX","deltaY","thresholdX","thresholdY","direction","then","cancelAnimationFrame","tracks","getTracks","track","stop","handleVideoLoaded","videoWidth","videoHeight","resetCalibration","className","children","autoPlay","playsInline","muted","onLoadedData","style","display","fileName","_jsxFileName","lineNumber","columnNumber","_c2","$RefreshReg$"],"sources":["C:/Users/kheri/Downloads/Bitcamp/bitcamp-2025/Bitcamp25/test-voice/src/FaceDetection.js"],"sourcesContent":["import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';\r\nimport * as tf from '@tensorflow/tfjs';\r\nimport '@tensorflow/tfjs-backend-webgl';\r\nimport '@tensorflow/tfjs-backend-wasm';\r\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\r\n\r\n// Initialize TensorFlow with the appropriate backend\r\nconst initializeTF = async () => {\r\n  // Try to use WebGL first for better performance, fallback to WASM\r\n  try {\r\n    await tf.setBackend('webgl');\r\n    console.log('Using WebGL backend for TensorFlow.js');\r\n  } catch (e) {\r\n    try {\r\n      await tf.setBackend('wasm');\r\n      console.log('Using WASM backend for TensorFlow.js');\r\n    } catch (e) {\r\n      console.error('Failed to initialize TensorFlow backend:', e);\r\n    }\r\n  }\r\n};\r\n\r\nconst FaceDetection = forwardRef(({ onHeadMovement, active = true, showDebug = false }, ref) => {\r\n  const videoRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n  const streamRef = useRef(null);\r\n  const modelRef = useRef(null);\r\n  const requestRef = useRef(null);\r\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\r\n  const lastPositionRef = useRef({ x: 0, y: 0 });\r\n  const centerPointRef = useRef({ x: 0, y: 0 });\r\n  const calibrationRef = useRef(false);\r\n  const [faceDetected, setFaceDetected] = useState(false);\r\n  \r\n  // Expose functions to parent component\r\n  useImperativeHandle(ref, () => ({\r\n    calibrate: () => {\r\n      calibrate();\r\n    },\r\n    isCalibrated: () => {\r\n      return calibrationRef.current;\r\n    },\r\n    isFaceDetected: () => {\r\n      return faceDetected;\r\n    }\r\n  }));\r\n  \r\n  // Load face detection model\r\n  const loadModel = async () => {\r\n    try {\r\n      // Load the MediaPipe Facemesh package using the current API\r\n      modelRef.current = await faceLandmarksDetection.createDetector(\r\n        faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,\r\n        {\r\n          runtime: 'mediapipe',\r\n          refineLandmarks: false,\r\n          maxFaces: 1\r\n        }\r\n      );\r\n      setIsModelLoaded(true);\r\n      console.log('Face detection model loaded');\r\n    } catch (error) {\r\n      console.error('Failed to load face detection model:', error);\r\n    }\r\n  };\r\n\r\n  // Set up webcam streaming\r\n  const setupCamera = async () => {\r\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\r\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get access to the webcam\r\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\r\n        video: { width: 640, height: 480, facingMode: 'user' }\r\n      });\r\n\r\n      // Set the video source\r\n      if (videoRef.current) {\r\n        videoRef.current.srcObject = streamRef.current;\r\n      }\r\n    } catch (error) {\r\n      console.error('Failed to access webcam:', error);\r\n    }\r\n  };\r\n\r\n  const calibrate = () => {\r\n    if (lastPositionRef.current) {\r\n      centerPointRef.current = { ...lastPositionRef.current };\r\n      calibrationRef.current = true;\r\n      console.log('Calibrated face position:', centerPointRef.current);\r\n    }\r\n  };\r\n\r\n  // Draw facial landmarks for debugging\r\n  const drawFacialLandmarks = (predictions, ctx) => {\r\n    if (!ctx || !predictions || predictions.length === 0) return;\r\n    \r\n    // Clear the canvas\r\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\r\n    \r\n    // Draw each prediction\r\n    predictions.forEach(prediction => {\r\n      // Draw facial keypoints\r\n      if (prediction.keypoints) {\r\n        for (let i = 0; i < prediction.keypoints.length; i++) {\r\n          const keypoint = prediction.keypoints[i];\r\n          \r\n          // Draw keypoint\r\n          ctx.beginPath();\r\n          ctx.arc(keypoint.x, keypoint.y, 1, 0, 2 * Math.PI);\r\n          ctx.fillStyle = 'aqua';\r\n          ctx.fill();\r\n        }\r\n      }\r\n      \r\n      // Find nose point\r\n      const nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\r\n      \r\n      if (nose) {\r\n        // Draw the nose point in a different color\r\n        ctx.beginPath();\r\n        ctx.arc(nose.x, nose.y, 5, 0, 2 * Math.PI);\r\n        ctx.fillStyle = 'green';\r\n        ctx.fill();\r\n        \r\n        // Draw a line from the center calibration point to current nose position\r\n        if (calibrationRef.current) {\r\n          ctx.beginPath();\r\n          ctx.moveTo(centerPointRef.current.x, centerPointRef.current.y);\r\n          ctx.lineTo(nose.x, nose.y);\r\n          ctx.strokeStyle = 'white';\r\n          ctx.lineWidth = 2;\r\n          ctx.stroke();\r\n          \r\n          // Draw the center calibration point\r\n          ctx.beginPath();\r\n          ctx.arc(centerPointRef.current.x, centerPointRef.current.y, 5, 0, 2 * Math.PI);\r\n          ctx.fillStyle = 'red';\r\n          ctx.fill();\r\n        }\r\n      }\r\n    });\r\n  };\r\n\r\n  // Detect faces and send head movement\r\n  const detectFaces = async () => {\r\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\r\n      requestRef.current = requestAnimationFrame(detectFaces);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get predictions using the updated API\r\n      const predictions = await modelRef.current.estimateFaces(videoRef.current, {\r\n        flipHorizontal: true\r\n      });\r\n\r\n      // Update face detected state\r\n      setFaceDetected(predictions.length > 0);\r\n      \r\n      // Draw landmarks if debug is enabled\r\n      if (showDebug && canvasRef.current) {\r\n        const ctx = canvasRef.current.getContext('2d');\r\n        drawFacialLandmarks(predictions, ctx);\r\n      }\r\n\r\n      if (predictions.length > 0) {\r\n        // Get nose point (middle of the face)\r\n        const nose = predictions[0].keypoints.find(kp => kp.name === 'nose_tip');\r\n        \r\n        if (nose) {\r\n          // Store current position\r\n          lastPositionRef.current = { x: nose.x, y: nose.y };\r\n          \r\n          // If we haven't calibrated yet, do it now\r\n          if (!calibrationRef.current) {\r\n            calibrate();\r\n            return;\r\n          }\r\n          \r\n          // Calculate difference from center (calibrated position)\r\n          const deltaX = nose.x - centerPointRef.current.x;\r\n          const deltaY = nose.y - centerPointRef.current.y;\r\n          \r\n          // Determine thresholds for movement (adjust these values as needed)\r\n          const thresholdX = 30;\r\n          const thresholdY = 30;\r\n          \r\n          // Determine movement direction\r\n          let direction = null;\r\n          \r\n          // Check horizontal movement (left/right)\r\n          if (deltaX < -thresholdX) {\r\n            direction = 'l'; // Left\r\n          } else if (deltaX > thresholdX) {\r\n            direction = 'r'; // Right\r\n          }\r\n          // Check vertical movement (up/down) - Y increases downward in image coordinates\r\n          else if (deltaY < -thresholdY) {\r\n            direction = 'u'; // Up\r\n          } else if (deltaY > thresholdY) {\r\n            direction = 'd'; // Down\r\n          }\r\n          \r\n          // Call the callback with the detected direction\r\n          if (direction && onHeadMovement) {\r\n            onHeadMovement(direction);\r\n          }\r\n        }\r\n      }\r\n    } catch (error) {\r\n      console.error('Error during face detection:', error);\r\n    }\r\n    \r\n    // Continue detection loop\r\n    requestRef.current = requestAnimationFrame(detectFaces);\r\n  };\r\n\r\n  // Initialize camera and model\r\n  useEffect(() => {\r\n    if (active) {\r\n      initializeTF().then(() => {\r\n        setupCamera().then(() => {\r\n          loadModel();\r\n        });\r\n      });\r\n    }\r\n\r\n    return () => {\r\n      // Clean up resources\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n        requestRef.current = null;\r\n      }\r\n      \r\n      if (streamRef.current) {\r\n        const tracks = streamRef.current.getTracks();\r\n        tracks.forEach(track => track.stop());\r\n        streamRef.current = null;\r\n      }\r\n    };\r\n  }, [active]);\r\n\r\n  // Start detection when model is loaded\r\n  useEffect(() => {\r\n    if (isModelLoaded && active) {\r\n      detectFaces();\r\n    }\r\n    \r\n    return () => {\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n      }\r\n    };\r\n  }, [isModelLoaded, active, showDebug]);\r\n\r\n  // Handle video loaded\r\n  const handleVideoLoaded = () => {\r\n    console.log('Video element is ready');\r\n    \r\n    // Set canvas dimensions to match video\r\n    if (canvasRef.current && videoRef.current) {\r\n      canvasRef.current.width = videoRef.current.videoWidth;\r\n      canvasRef.current.height = videoRef.current.videoHeight;\r\n    }\r\n  };\r\n\r\n  // Reset calibration with a function that can be exposed if needed\r\n  const resetCalibration = () => {\r\n    calibrationRef.current = false;\r\n    console.log('Calibration reset');\r\n  };\r\n\r\n  return (\r\n    <div className={`face-detection ${showDebug ? 'debug-mode' : ''}`}>\r\n      <video \r\n        ref={videoRef}\r\n        width=\"320\"\r\n        height=\"240\"\r\n        autoPlay\r\n        playsInline\r\n        muted\r\n        onLoadedData={handleVideoLoaded}\r\n        style={{ display: showDebug ? 'block' : 'none' }}\r\n        className=\"face-video\"\r\n      />\r\n      \r\n      {showDebug && (\r\n        <canvas \r\n          ref={canvasRef}\r\n          width=\"320\"\r\n          height=\"240\"\r\n          className=\"landmarks-canvas\"\r\n        />\r\n      )}\r\n      \r\n      {!isModelLoaded && active && (\r\n        <div className=\"loading-model\">Loading face detection model...</div>\r\n      )}\r\n      \r\n      {faceDetected && active && !showDebug && (\r\n        <div className=\"face-detection-status\">\r\n          Face {calibrationRef.current ? 'Tracked' : 'Detected'}\r\n        </div>\r\n      )}\r\n    </div>\r\n  );\r\n});\r\n\r\nexport default FaceDetection; "],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,EAAEC,mBAAmB,EAAEC,UAAU,QAAQ,OAAO;AAC3F,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,gCAAgC;AACvC,OAAO,+BAA+B;AACtC,OAAO,KAAKC,sBAAsB,MAAM,6CAA6C;;AAErF;AAAA,SAAAC,MAAA,IAAAC,OAAA;AACA,MAAMC,YAAY,GAAG,MAAAA,CAAA,KAAY;EAC/B;EACA,IAAI;IACF,MAAMJ,EAAE,CAACK,UAAU,CAAC,OAAO,CAAC;IAC5BC,OAAO,CAACC,GAAG,CAAC,uCAAuC,CAAC;EACtD,CAAC,CAAC,OAAOC,CAAC,EAAE;IACV,IAAI;MACF,MAAMR,EAAE,CAACK,UAAU,CAAC,MAAM,CAAC;MAC3BC,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;IACrD,CAAC,CAAC,OAAOC,CAAC,EAAE;MACVF,OAAO,CAACG,KAAK,CAAC,0CAA0C,EAAED,CAAC,CAAC;IAC9D;EACF;AACF,CAAC;AAED,MAAME,aAAa,gBAAAC,EAAA,cAAGZ,UAAU,CAAAa,EAAA,GAAAD,EAAA,CAAC,CAAC;EAAEE,cAAc;EAAEC,MAAM,GAAG,IAAI;EAAEC,SAAS,GAAG;AAAM,CAAC,EAAEC,GAAG,KAAK;EAAAL,EAAA;EAC9F,MAAMM,QAAQ,GAAGrB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMsB,SAAS,GAAGtB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMuB,SAAS,GAAGvB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMwB,QAAQ,GAAGxB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMyB,UAAU,GAAGzB,MAAM,CAAC,IAAI,CAAC;EAC/B,MAAM,CAAC0B,aAAa,EAAEC,gBAAgB,CAAC,GAAG1B,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAM2B,eAAe,GAAG5B,MAAM,CAAC;IAAE6B,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC9C,MAAMC,cAAc,GAAG/B,MAAM,CAAC;IAAE6B,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC7C,MAAME,cAAc,GAAGhC,MAAM,CAAC,KAAK,CAAC;EACpC,MAAM,CAACiC,YAAY,EAAEC,eAAe,CAAC,GAAGjC,QAAQ,CAAC,KAAK,CAAC;;EAEvD;EACAC,mBAAmB,CAACkB,GAAG,EAAE,OAAO;IAC9Be,SAAS,EAAEA,CAAA,KAAM;MACfA,SAAS,CAAC,CAAC;IACb,CAAC;IACDC,YAAY,EAAEA,CAAA,KAAM;MAClB,OAAOJ,cAAc,CAACK,OAAO;IAC/B,CAAC;IACDC,cAAc,EAAEA,CAAA,KAAM;MACpB,OAAOL,YAAY;IACrB;EACF,CAAC,CAAC,CAAC;;EAEH;EACA,MAAMM,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACF;MACAf,QAAQ,CAACa,OAAO,GAAG,MAAMhC,sBAAsB,CAACmC,cAAc,CAC5DnC,sBAAsB,CAACoC,eAAe,CAACC,iBAAiB,EACxD;QACEC,OAAO,EAAE,WAAW;QACpBC,eAAe,EAAE,KAAK;QACtBC,QAAQ,EAAE;MACZ,CACF,CAAC;MACDlB,gBAAgB,CAAC,IAAI,CAAC;MACtBjB,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAC;IAC5C,CAAC,CAAC,OAAOE,KAAK,EAAE;MACdH,OAAO,CAACG,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;IAC9D;EACF,CAAC;;EAED;EACA,MAAMiC,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAACC,SAAS,CAACC,YAAY,IAAI,CAACD,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;MACnEvC,OAAO,CAACG,KAAK,CAAC,+DAA+D,CAAC;MAC9E;IACF;IAEA,IAAI;MACF;MACAU,SAAS,CAACc,OAAO,GAAG,MAAMU,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAC5DC,KAAK,EAAE;UAAEC,KAAK,EAAE,GAAG;UAAEC,MAAM,EAAE,GAAG;UAAEC,UAAU,EAAE;QAAO;MACvD,CAAC,CAAC;;MAEF;MACA,IAAIhC,QAAQ,CAACgB,OAAO,EAAE;QACpBhB,QAAQ,CAACgB,OAAO,CAACiB,SAAS,GAAG/B,SAAS,CAACc,OAAO;MAChD;IACF,CAAC,CAAC,OAAOxB,KAAK,EAAE;MACdH,OAAO,CAACG,KAAK,CAAC,0BAA0B,EAAEA,KAAK,CAAC;IAClD;EACF,CAAC;EAED,MAAMsB,SAAS,GAAGA,CAAA,KAAM;IACtB,IAAIP,eAAe,CAACS,OAAO,EAAE;MAC3BN,cAAc,CAACM,OAAO,GAAG;QAAE,GAAGT,eAAe,CAACS;MAAQ,CAAC;MACvDL,cAAc,CAACK,OAAO,GAAG,IAAI;MAC7B3B,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEoB,cAAc,CAACM,OAAO,CAAC;IAClE;EACF,CAAC;;EAED;EACA,MAAMkB,mBAAmB,GAAGA,CAACC,WAAW,EAAEC,GAAG,KAAK;IAChD,IAAI,CAACA,GAAG,IAAI,CAACD,WAAW,IAAIA,WAAW,CAACE,MAAM,KAAK,CAAC,EAAE;;IAEtD;IACAD,GAAG,CAACE,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEF,GAAG,CAACG,MAAM,CAACT,KAAK,EAAEM,GAAG,CAACG,MAAM,CAACR,MAAM,CAAC;;IAExD;IACAI,WAAW,CAACK,OAAO,CAACC,UAAU,IAAI;MAChC;MACA,IAAIA,UAAU,CAACC,SAAS,EAAE;QACxB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,UAAU,CAACC,SAAS,CAACL,MAAM,EAAEM,CAAC,EAAE,EAAE;UACpD,MAAMC,QAAQ,GAAGH,UAAU,CAACC,SAAS,CAACC,CAAC,CAAC;;UAExC;UACAP,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACU,GAAG,CAACF,QAAQ,CAACpC,CAAC,EAAEoC,QAAQ,CAACnC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGsC,IAAI,CAACC,EAAE,CAAC;UAClDZ,GAAG,CAACa,SAAS,GAAG,MAAM;UACtBb,GAAG,CAACc,IAAI,CAAC,CAAC;QACZ;MACF;;MAEA;MACA,MAAMC,IAAI,GAAGV,UAAU,CAACC,SAAS,CAACU,IAAI,CAACC,EAAE,IAAIA,EAAE,CAACC,IAAI,KAAK,UAAU,CAAC;MAEpE,IAAIH,IAAI,EAAE;QACR;QACAf,GAAG,CAACS,SAAS,CAAC,CAAC;QACfT,GAAG,CAACU,GAAG,CAACK,IAAI,CAAC3C,CAAC,EAAE2C,IAAI,CAAC1C,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGsC,IAAI,CAACC,EAAE,CAAC;QAC1CZ,GAAG,CAACa,SAAS,GAAG,OAAO;QACvBb,GAAG,CAACc,IAAI,CAAC,CAAC;;QAEV;QACA,IAAIvC,cAAc,CAACK,OAAO,EAAE;UAC1BoB,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACmB,MAAM,CAAC7C,cAAc,CAACM,OAAO,CAACR,CAAC,EAAEE,cAAc,CAACM,OAAO,CAACP,CAAC,CAAC;UAC9D2B,GAAG,CAACoB,MAAM,CAACL,IAAI,CAAC3C,CAAC,EAAE2C,IAAI,CAAC1C,CAAC,CAAC;UAC1B2B,GAAG,CAACqB,WAAW,GAAG,OAAO;UACzBrB,GAAG,CAACsB,SAAS,GAAG,CAAC;UACjBtB,GAAG,CAACuB,MAAM,CAAC,CAAC;;UAEZ;UACAvB,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACU,GAAG,CAACpC,cAAc,CAACM,OAAO,CAACR,CAAC,EAAEE,cAAc,CAACM,OAAO,CAACP,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGsC,IAAI,CAACC,EAAE,CAAC;UAC9EZ,GAAG,CAACa,SAAS,GAAG,KAAK;UACrBb,GAAG,CAACc,IAAI,CAAC,CAAC;QACZ;MACF;IACF,CAAC,CAAC;EACJ,CAAC;;EAED;EACA,MAAMU,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAACzD,QAAQ,CAACa,OAAO,IAAI,CAAChB,QAAQ,CAACgB,OAAO,IAAI,CAAChB,QAAQ,CAACgB,OAAO,CAAC6C,UAAU,KAAK,CAAC,EAAE;MAChFzD,UAAU,CAACY,OAAO,GAAG8C,qBAAqB,CAACF,WAAW,CAAC;MACvD;IACF;IAEA,IAAI;MACF;MACA,MAAMzB,WAAW,GAAG,MAAMhC,QAAQ,CAACa,OAAO,CAAC+C,aAAa,CAAC/D,QAAQ,CAACgB,OAAO,EAAE;QACzEgD,cAAc,EAAE;MAClB,CAAC,CAAC;;MAEF;MACAnD,eAAe,CAACsB,WAAW,CAACE,MAAM,GAAG,CAAC,CAAC;;MAEvC;MACA,IAAIvC,SAAS,IAAIG,SAAS,CAACe,OAAO,EAAE;QAClC,MAAMoB,GAAG,GAAGnC,SAAS,CAACe,OAAO,CAACiD,UAAU,CAAC,IAAI,CAAC;QAC9C/B,mBAAmB,CAACC,WAAW,EAAEC,GAAG,CAAC;MACvC;MAEA,IAAID,WAAW,CAACE,MAAM,GAAG,CAAC,EAAE;QAC1B;QACA,MAAMc,IAAI,GAAGhB,WAAW,CAAC,CAAC,CAAC,CAACO,SAAS,CAACU,IAAI,CAACC,EAAE,IAAIA,EAAE,CAACC,IAAI,KAAK,UAAU,CAAC;QAExE,IAAIH,IAAI,EAAE;UACR;UACA5C,eAAe,CAACS,OAAO,GAAG;YAAER,CAAC,EAAE2C,IAAI,CAAC3C,CAAC;YAAEC,CAAC,EAAE0C,IAAI,CAAC1C;UAAE,CAAC;;UAElD;UACA,IAAI,CAACE,cAAc,CAACK,OAAO,EAAE;YAC3BF,SAAS,CAAC,CAAC;YACX;UACF;;UAEA;UACA,MAAMoD,MAAM,GAAGf,IAAI,CAAC3C,CAAC,GAAGE,cAAc,CAACM,OAAO,CAACR,CAAC;UAChD,MAAM2D,MAAM,GAAGhB,IAAI,CAAC1C,CAAC,GAAGC,cAAc,CAACM,OAAO,CAACP,CAAC;;UAEhD;UACA,MAAM2D,UAAU,GAAG,EAAE;UACrB,MAAMC,UAAU,GAAG,EAAE;;UAErB;UACA,IAAIC,SAAS,GAAG,IAAI;;UAEpB;UACA,IAAIJ,MAAM,GAAG,CAACE,UAAU,EAAE;YACxBE,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB,CAAC,MAAM,IAAIJ,MAAM,GAAGE,UAAU,EAAE;YAC9BE,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB;UACA;UAAA,KACK,IAAIH,MAAM,GAAG,CAACE,UAAU,EAAE;YAC7BC,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB,CAAC,MAAM,IAAIH,MAAM,GAAGE,UAAU,EAAE;YAC9BC,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB;;UAEA;UACA,IAAIA,SAAS,IAAI1E,cAAc,EAAE;YAC/BA,cAAc,CAAC0E,SAAS,CAAC;UAC3B;QACF;MACF;IACF,CAAC,CAAC,OAAO9E,KAAK,EAAE;MACdH,OAAO,CAACG,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;IACtD;;IAEA;IACAY,UAAU,CAACY,OAAO,GAAG8C,qBAAqB,CAACF,WAAW,CAAC;EACzD,CAAC;;EAED;EACAlF,SAAS,CAAC,MAAM;IACd,IAAImB,MAAM,EAAE;MACVV,YAAY,CAAC,CAAC,CAACoF,IAAI,CAAC,MAAM;QACxB9C,WAAW,CAAC,CAAC,CAAC8C,IAAI,CAAC,MAAM;UACvBrD,SAAS,CAAC,CAAC;QACb,CAAC,CAAC;MACJ,CAAC,CAAC;IACJ;IAEA,OAAO,MAAM;MACX;MACA,IAAId,UAAU,CAACY,OAAO,EAAE;QACtBwD,oBAAoB,CAACpE,UAAU,CAACY,OAAO,CAAC;QACxCZ,UAAU,CAACY,OAAO,GAAG,IAAI;MAC3B;MAEA,IAAId,SAAS,CAACc,OAAO,EAAE;QACrB,MAAMyD,MAAM,GAAGvE,SAAS,CAACc,OAAO,CAAC0D,SAAS,CAAC,CAAC;QAC5CD,MAAM,CAACjC,OAAO,CAACmC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QACrC1E,SAAS,CAACc,OAAO,GAAG,IAAI;MAC1B;IACF,CAAC;EACH,CAAC,EAAE,CAACnB,MAAM,CAAC,CAAC;;EAEZ;EACAnB,SAAS,CAAC,MAAM;IACd,IAAI2B,aAAa,IAAIR,MAAM,EAAE;MAC3B+D,WAAW,CAAC,CAAC;IACf;IAEA,OAAO,MAAM;MACX,IAAIxD,UAAU,CAACY,OAAO,EAAE;QACtBwD,oBAAoB,CAACpE,UAAU,CAACY,OAAO,CAAC;MAC1C;IACF,CAAC;EACH,CAAC,EAAE,CAACX,aAAa,EAAER,MAAM,EAAEC,SAAS,CAAC,CAAC;;EAEtC;EACA,MAAM+E,iBAAiB,GAAGA,CAAA,KAAM;IAC9BxF,OAAO,CAACC,GAAG,CAAC,wBAAwB,CAAC;;IAErC;IACA,IAAIW,SAAS,CAACe,OAAO,IAAIhB,QAAQ,CAACgB,OAAO,EAAE;MACzCf,SAAS,CAACe,OAAO,CAACc,KAAK,GAAG9B,QAAQ,CAACgB,OAAO,CAAC8D,UAAU;MACrD7E,SAAS,CAACe,OAAO,CAACe,MAAM,GAAG/B,QAAQ,CAACgB,OAAO,CAAC+D,WAAW;IACzD;EACF,CAAC;;EAED;EACA,MAAMC,gBAAgB,GAAGA,CAAA,KAAM;IAC7BrE,cAAc,CAACK,OAAO,GAAG,KAAK;IAC9B3B,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;EAClC,CAAC;EAED,oBACEJ,OAAA;IAAK+F,SAAS,EAAE,kBAAkBnF,SAAS,GAAG,YAAY,GAAG,EAAE,EAAG;IAAAoF,QAAA,gBAChEhG,OAAA;MACEa,GAAG,EAAEC,QAAS;MACd8B,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZoD,QAAQ;MACRC,WAAW;MACXC,KAAK;MACLC,YAAY,EAAET,iBAAkB;MAChCU,KAAK,EAAE;QAAEC,OAAO,EAAE1F,SAAS,GAAG,OAAO,GAAG;MAAO,CAAE;MACjDmF,SAAS,EAAC;IAAY;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACvB,CAAC,EAED9F,SAAS,iBACRZ,OAAA;MACEa,GAAG,EAAEE,SAAU;MACf6B,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZkD,SAAS,EAAC;IAAkB;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7B,CACF,EAEA,CAACvF,aAAa,IAAIR,MAAM,iBACvBX,OAAA;MAAK+F,SAAS,EAAC,eAAe;MAAAC,QAAA,EAAC;IAA+B;MAAAO,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CACpE,EAEAhF,YAAY,IAAIf,MAAM,IAAI,CAACC,SAAS,iBACnCZ,OAAA;MAAK+F,SAAS,EAAC,uBAAuB;MAAAC,QAAA,GAAC,OAChC,EAACvE,cAAc,CAACK,OAAO,GAAG,SAAS,GAAG,UAAU;IAAA;MAAAyE,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAClD,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC,kCAAC;AAACC,GAAA,GAhSGpG,aAAa;AAkSnB,eAAeA,aAAa;AAAC,IAAAE,EAAA,EAAAkG,GAAA;AAAAC,YAAA,CAAAnG,EAAA;AAAAmG,YAAA,CAAAD,GAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}