{"ast":null,"code":"/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { LRNGrad } from '@tensorflow/tfjs-core';\nlet wasmLRNGrad;\nfunction setup(backend) {\n  wasmLRNGrad = backend.wasm.cwrap(LRNGrad, null, ['number', 'number', 'number', 'number', 'number', 'number', 'number', 'number', 'number' // beta\n  ]);\n}\nexport function lrnGrad(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    x,\n    y,\n    dy\n  } = inputs;\n  const {\n    depthRadius,\n    bias,\n    alpha,\n    beta\n  } = attrs;\n  if (x.dtype !== 'float32' || y.dtype !== 'float32' || dy.dtype !== 'float32') {\n    throw new Error('LRNGrad error: x, y, and dy must have dtype float32');\n  }\n  const dx = backend.makeOutput(x.shape, x.dtype);\n  wasmLRNGrad(backend.dataIdMap.get(x.dataId).id, backend.dataIdMap.get(y.dataId).id, backend.dataIdMap.get(dy.dataId).id, backend.dataIdMap.get(dx.dataId).id, /*channels=*/dy.shape[3], depthRadius, bias, alpha, beta);\n  return dx;\n}\nexport const lrnGradConfig = {\n  kernelName: LRNGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: lrnGrad\n};","map":{"version":3,"names":["LRNGrad","wasmLRNGrad","setup","backend","wasm","cwrap","lrnGrad","args","inputs","attrs","x","y","dy","depthRadius","bias","alpha","beta","dtype","Error","dx","makeOutput","shape","dataIdMap","get","dataId","id","lrnGradConfig","kernelName","backendName","setupFunc","kernelFunc"],"sources":["C:\\Users\\kheri\\Downloads\\Bitcamp\\bitcamp-2025\\Bitcamp25\\tfjs-backend-wasm\\src\\kernels\\LRNGrad.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2023 Google LLC.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, LRNGrad, LRNGradAttrs, LRNGradInputs, TensorInfo} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nlet wasmLRNGrad: (\n    xId: number, yId: number, dyId: number, dxId: number, channels: number,\n    depthRadius: number, bias: number, alpha: number, beta: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmLRNGrad = backend.wasm.cwrap(LRNGrad, null, [\n    'number',  // xId\n    'number',  // yId\n    'number',  // dyId\n    'number',  // dxId\n    'number',  // channels\n    'number',  // depthRadius\n    'number',  // bias\n    'number',  // alpha\n    'number',  // beta\n  ]);\n}\n\nexport function lrnGrad(args: {\n  inputs: LRNGradInputs,\n  attrs: LRNGradAttrs,\n  backend: BackendWasm,\n}): TensorInfo {\n  const {inputs, backend, attrs} = args;\n  const {x, y, dy} = inputs;\n  const {depthRadius, bias, alpha, beta} = attrs;\n\n  if (x.dtype !== 'float32' || y.dtype !== 'float32' ||\n      dy.dtype !== 'float32') {\n    throw new Error('LRNGrad error: x, y, and dy must have dtype float32');\n  }\n\n  const dx = backend.makeOutput(x.shape, x.dtype);\n\n  wasmLRNGrad(\n      backend.dataIdMap.get(x.dataId).id,\n      backend.dataIdMap.get(y.dataId).id,\n      backend.dataIdMap.get(dy.dataId).id,\n      backend.dataIdMap.get(dx.dataId).id,\n      /*channels=*/dy.shape[3],\n      depthRadius,\n      bias,\n      alpha,\n      beta,\n  );\n  return dx;\n}\n\nexport const lrnGradConfig: KernelConfig = {\n  kernelName: LRNGrad,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: lrnGrad as unknown as KernelFunc\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAkCA,OAAO,QAAgD,uBAAuB;AAIhH,IAAIC,WAEuE;AAE3E,SAASC,KAAKA,CAACC,OAAoB;EACjCF,WAAW,GAAGE,OAAO,CAACC,IAAI,CAACC,KAAK,CAACL,OAAO,EAAE,IAAI,EAAE,CAC9C,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,CAAG;EAAA,CACZ,CAAC;AACJ;AAEA,OAAM,SAAUM,OAAOA,CAACC,IAIvB;EACC,MAAM;IAACC,MAAM;IAAEL,OAAO;IAAEM;EAAK,CAAC,GAAGF,IAAI;EACrC,MAAM;IAACG,CAAC;IAAEC,CAAC;IAAEC;EAAE,CAAC,GAAGJ,MAAM;EACzB,MAAM;IAACK,WAAW;IAAEC,IAAI;IAAEC,KAAK;IAAEC;EAAI,CAAC,GAAGP,KAAK;EAE9C,IAAIC,CAAC,CAACO,KAAK,KAAK,SAAS,IAAIN,CAAC,CAACM,KAAK,KAAK,SAAS,IAC9CL,EAAE,CAACK,KAAK,KAAK,SAAS,EAAE;IAC1B,MAAM,IAAIC,KAAK,CAAC,qDAAqD,CAAC;;EAGxE,MAAMC,EAAE,GAAGhB,OAAO,CAACiB,UAAU,CAACV,CAAC,CAACW,KAAK,EAAEX,CAAC,CAACO,KAAK,CAAC;EAE/ChB,WAAW,CACPE,OAAO,CAACmB,SAAS,CAACC,GAAG,CAACb,CAAC,CAACc,MAAM,CAAC,CAACC,EAAE,EAClCtB,OAAO,CAACmB,SAAS,CAACC,GAAG,CAACZ,CAAC,CAACa,MAAM,CAAC,CAACC,EAAE,EAClCtB,OAAO,CAACmB,SAAS,CAACC,GAAG,CAACX,EAAE,CAACY,MAAM,CAAC,CAACC,EAAE,EACnCtB,OAAO,CAACmB,SAAS,CAACC,GAAG,CAACJ,EAAE,CAACK,MAAM,CAAC,CAACC,EAAE,EACnC,aAAab,EAAE,CAACS,KAAK,CAAC,CAAC,CAAC,EACxBR,WAAW,EACXC,IAAI,EACJC,KAAK,EACLC,IAAI,CACP;EACD,OAAOG,EAAE;AACX;AAEA,OAAO,MAAMO,aAAa,GAAiB;EACzCC,UAAU,EAAE3B,OAAO;EACnB4B,WAAW,EAAE,MAAM;EACnBC,SAAS,EAAE3B,KAAK;EAChB4B,UAAU,EAAExB;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}