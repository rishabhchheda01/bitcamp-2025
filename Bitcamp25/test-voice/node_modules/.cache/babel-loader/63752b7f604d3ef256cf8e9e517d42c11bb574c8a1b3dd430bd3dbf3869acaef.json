{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { PadV2, util } from '@tensorflow/tfjs-core';\nimport { fill } from './Fill';\nimport { CppDType } from './types';\nlet wasmPadV2;\nfunction setup(backend) {\n  wasmPadV2 = backend.wasm.cwrap(PadV2, null /* void */, ['number', 'array', 'number', 'number', 'array', 'array', 'number', 'number' // outId\n  ]);\n}\nfunction pad(args) {\n  const {\n    inputs: {\n      x\n    },\n    backend,\n    attrs: {\n      paddings,\n      constantValue\n    }\n  } = args;\n  const outShape = paddings.map((p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n  if (util.sizeFromShape(x.shape) === 0) {\n    // Short-circuit the computation, since x doesn't have value, only\n    // the shape is used to compute output shape to pad.\n    return fill({\n      backend,\n      attrs: {\n        shape: outShape,\n        value: constantValue,\n        dtype: x.dtype\n      }\n    });\n  }\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const out = backend.makeOutput(outShape, x.dtype);\n  const outTensorData = backend.dataIdMap.get(out.dataId);\n  const outId = outTensorData.id;\n  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n  const prePaddingsFlat = paddings.map(padTuple => padTuple[0]);\n  const postPaddingsFlat = paddings.map(padTuple => padTuple[1]);\n  const prePaddingsBytes = new Uint8Array(new Int32Array(prePaddingsFlat).buffer);\n  const postPaddingsBytes = new Uint8Array(new Int32Array(postPaddingsFlat).buffer);\n  wasmPadV2(xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes, postPaddingsBytes, constantValue, outId);\n  return out;\n}\nexport const padV2Config = {\n  kernelName: PadV2,\n  backendName: 'wasm',\n  kernelFunc: pad,\n  setupFunc: setup\n};","map":{"version":3,"names":["PadV2","util","fill","CppDType","wasmPadV2","setup","backend","wasm","cwrap","pad","args","inputs","x","attrs","paddings","constantValue","outShape","map","p","i","shape","sizeFromShape","value","dtype","xId","dataIdMap","get","dataId","id","out","makeOutput","outTensorData","outId","xShapeBytes","Uint8Array","Int32Array","buffer","prePaddingsFlat","padTuple","postPaddingsFlat","prePaddingsBytes","postPaddingsBytes","length","padV2Config","kernelName","backendName","kernelFunc","setupFunc"],"sources":["C:\\Users\\kheri\\Downloads\\Bitcamp\\bitcamp-2025\\Bitcamp25\\tfjs-backend-wasm\\src\\kernels\\PadV2.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {KernelConfig, KernelFunc, PadV2, PadV2Attrs, PadV2Inputs, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {fill} from './Fill';\n\nimport {CppDType} from './types';\n\nlet wasmPadV2: (\n    xId: number, xShapeBytes: Uint8Array, xShapeLength: number, xDtype: number,\n    prePaddingsBytes: Uint8Array, postPaddingsBytes: Uint8Array,\n    constantValue: number, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmPadV2 = backend.wasm.cwrap(PadV2, null /* void */, [\n    'number',  // xId\n    'array',   // x.shape\n    'number',  // x.shape.length\n    'number',  // x.dtype\n    'array',   // pre-paddings\n    'array',   // post-paddings\n    'number',  // constantValue\n    'number',  // outId\n  ]);\n}\n\nfunction pad(\n    args: {inputs: PadV2Inputs, backend: BackendWasm, attrs: PadV2Attrs}) {\n  const {inputs: {x}, backend, attrs: {paddings, constantValue}} = args;\n\n  const outShape = paddings.map(\n      (p, i) => p[0] /* beforePad */ + x.shape[i] + p[1] /* afterPad */);\n\n  if (util.sizeFromShape(x.shape) === 0) {\n    // Short-circuit the computation, since x doesn't have value, only\n    // the shape is used to compute output shape to pad.\n    return fill({\n      backend,\n      attrs: {shape: outShape, value: constantValue, dtype: x.dtype}\n    });\n  }\n\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  const out = backend.makeOutput(outShape, x.dtype);\n  const outTensorData = backend.dataIdMap.get(out.dataId);\n  const outId = outTensorData.id;\n\n  const xShapeBytes = new Uint8Array(new Int32Array(x.shape).buffer);\n\n  const prePaddingsFlat = paddings.map(padTuple => padTuple[0]);\n  const postPaddingsFlat = paddings.map(padTuple => padTuple[1]);\n  const prePaddingsBytes =\n      new Uint8Array(new Int32Array(prePaddingsFlat).buffer);\n  const postPaddingsBytes =\n      new Uint8Array(new Int32Array(postPaddingsFlat).buffer);\n\n  wasmPadV2(\n      xId, xShapeBytes, x.shape.length, CppDType[x.dtype], prePaddingsBytes,\n      postPaddingsBytes, constantValue, outId);\n  return out;\n}\n\nexport const padV2Config: KernelConfig = {\n  kernelName: PadV2,\n  backendName: 'wasm',\n  kernelFunc: pad as unknown as KernelFunc,\n  setupFunc: setup\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAkCA,KAAK,EAA2BC,IAAI,QAAO,uBAAuB;AAIpG,SAAQC,IAAI,QAAO,QAAQ;AAE3B,SAAQC,QAAQ,QAAO,SAAS;AAEhC,IAAIC,SAG6C;AAEjD,SAASC,KAAKA,CAACC,OAAoB;EACjCF,SAAS,GAAGE,OAAO,CAACC,IAAI,CAACC,KAAK,CAACR,KAAK,EAAE,IAAI,CAAC,YAAY,CACrD,QAAQ,EACR,OAAO,EACP,QAAQ,EACR,QAAQ,EACR,OAAO,EACP,OAAO,EACP,QAAQ,EACR,QAAQ,CAAG;EAAA,CACZ,CAAC;AACJ;AAEA,SAASS,GAAGA,CACRC,IAAoE;EACtE,MAAM;IAACC,MAAM,EAAE;MAACC;IAAC,CAAC;IAAEN,OAAO;IAAEO,KAAK,EAAE;MAACC,QAAQ;MAAEC;IAAa;EAAC,CAAC,GAAGL,IAAI;EAErE,MAAMM,QAAQ,GAAGF,QAAQ,CAACG,GAAG,CACzB,CAACC,CAAC,EAAEC,CAAC,KAAKD,CAAC,CAAC,CAAC,CAAC,CAAC,kBAAkBN,CAAC,CAACQ,KAAK,CAACD,CAAC,CAAC,GAAGD,CAAC,CAAC,CAAC,CAAC,CAAC,cAAc,CAAC;EAEtE,IAAIjB,IAAI,CAACoB,aAAa,CAACT,CAAC,CAACQ,KAAK,CAAC,KAAK,CAAC,EAAE;IACrC;IACA;IACA,OAAOlB,IAAI,CAAC;MACVI,OAAO;MACPO,KAAK,EAAE;QAACO,KAAK,EAAEJ,QAAQ;QAAEM,KAAK,EAAEP,aAAa;QAAEQ,KAAK,EAAEX,CAAC,CAACW;MAAK;KAC9D,CAAC;;EAGJ,MAAMC,GAAG,GAAGlB,OAAO,CAACmB,SAAS,CAACC,GAAG,CAACd,CAAC,CAACe,MAAM,CAAC,CAACC,EAAE;EAC9C,MAAMC,GAAG,GAAGvB,OAAO,CAACwB,UAAU,CAACd,QAAQ,EAAEJ,CAAC,CAACW,KAAK,CAAC;EACjD,MAAMQ,aAAa,GAAGzB,OAAO,CAACmB,SAAS,CAACC,GAAG,CAACG,GAAG,CAACF,MAAM,CAAC;EACvD,MAAMK,KAAK,GAAGD,aAAa,CAACH,EAAE;EAE9B,MAAMK,WAAW,GAAG,IAAIC,UAAU,CAAC,IAAIC,UAAU,CAACvB,CAAC,CAACQ,KAAK,CAAC,CAACgB,MAAM,CAAC;EAElE,MAAMC,eAAe,GAAGvB,QAAQ,CAACG,GAAG,CAACqB,QAAQ,IAAIA,QAAQ,CAAC,CAAC,CAAC,CAAC;EAC7D,MAAMC,gBAAgB,GAAGzB,QAAQ,CAACG,GAAG,CAACqB,QAAQ,IAAIA,QAAQ,CAAC,CAAC,CAAC,CAAC;EAC9D,MAAME,gBAAgB,GAClB,IAAIN,UAAU,CAAC,IAAIC,UAAU,CAACE,eAAe,CAAC,CAACD,MAAM,CAAC;EAC1D,MAAMK,iBAAiB,GACnB,IAAIP,UAAU,CAAC,IAAIC,UAAU,CAACI,gBAAgB,CAAC,CAACH,MAAM,CAAC;EAE3DhC,SAAS,CACLoB,GAAG,EAAES,WAAW,EAAErB,CAAC,CAACQ,KAAK,CAACsB,MAAM,EAAEvC,QAAQ,CAACS,CAAC,CAACW,KAAK,CAAC,EAAEiB,gBAAgB,EACrEC,iBAAiB,EAAE1B,aAAa,EAAEiB,KAAK,CAAC;EAC5C,OAAOH,GAAG;AACZ;AAEA,OAAO,MAAMc,WAAW,GAAiB;EACvCC,UAAU,EAAE5C,KAAK;EACjB6C,WAAW,EAAE,MAAM;EACnBC,UAAU,EAAErC,GAA4B;EACxCsC,SAAS,EAAE1C;CACZ","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}