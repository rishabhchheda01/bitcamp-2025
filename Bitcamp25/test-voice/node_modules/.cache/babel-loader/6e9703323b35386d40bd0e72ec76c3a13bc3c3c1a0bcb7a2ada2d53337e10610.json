{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\kheri\\\\Downloads\\\\Bitcamp\\\\bitcamp-2025\\\\Bitcamp25\\\\test-voice\\\\src\\\\FaceDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef, useState } from 'react';\nimport * as tf from '@tensorflow/tfjs';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst FaceDetection = ({\n  onHeadMovement,\n  active = true\n}) => {\n  _s();\n  const videoRef = useRef(null);\n  const streamRef = useRef(null);\n  const modelRef = useRef(null);\n  const requestRef = useRef(null);\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\n  const lastPositionRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const centerPointRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const calibrationRef = useRef(false);\n\n  // Load face detection model\n  const loadModel = async () => {\n    try {\n      // Load the MediaPipe Facemesh package\n      modelRef.current = await faceLandmarksDetection.load(faceLandmarksDetection.SupportedPackages.mediapipeFacemesh, {\n        maxFaces: 1\n      });\n      setIsModelLoaded(true);\n      console.log('Face detection model loaded');\n    } catch (error) {\n      console.error('Failed to load face detection model:', error);\n    }\n  };\n\n  // Set up webcam streaming\n  const setupCamera = async () => {\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\n      return;\n    }\n    try {\n      // Get access to the webcam\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\n        video: {\n          width: 640,\n          height: 480,\n          facingMode: 'user'\n        }\n      });\n\n      // Set the video source\n      if (videoRef.current) {\n        videoRef.current.srcObject = streamRef.current;\n      }\n    } catch (error) {\n      console.error('Failed to access webcam:', error);\n    }\n  };\n  const calibrate = () => {\n    if (lastPositionRef.current) {\n      centerPointRef.current = {\n        ...lastPositionRef.current\n      };\n      calibrationRef.current = true;\n      console.log('Calibrated face position:', centerPointRef.current);\n    }\n  };\n\n  // Detect faces and send head movement\n  const detectFaces = async () => {\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\n      requestRef.current = requestAnimationFrame(detectFaces);\n      return;\n    }\n    try {\n      // Get predictions\n      const predictions = await modelRef.current.estimateFaces({\n        input: videoRef.current,\n        returnTensors: false,\n        flipHorizontal: true,\n        predictIrises: false\n      });\n      if (predictions.length > 0) {\n        // Get nose point (middle of the face)\n        const nose = predictions[0].annotations.noseTip[0];\n\n        // Store current position\n        lastPositionRef.current = {\n          x: nose[0],\n          y: nose[1]\n        };\n\n        // If we haven't calibrated yet, do it now\n        if (!calibrationRef.current) {\n          calibrate();\n          return;\n        }\n\n        // Calculate difference from center (calibrated position)\n        const deltaX = nose[0] - centerPointRef.current.x;\n        const deltaY = nose[1] - centerPointRef.current.y;\n\n        // Determine thresholds for movement (adjust these values as needed)\n        const thresholdX = 30;\n        const thresholdY = 30;\n\n        // Determine movement direction\n        let direction = null;\n\n        // Check horizontal movement (left/right)\n        if (deltaX < -thresholdX) {\n          direction = 'l'; // Left\n        } else if (deltaX > thresholdX) {\n          direction = 'r'; // Right\n        }\n        // Check vertical movement (up/down) - Y increases downward in image coordinates\n        else if (deltaY < -thresholdY) {\n          direction = 'u'; // Up\n        } else if (deltaY > thresholdY) {\n          direction = 'd'; // Down\n        }\n\n        // Call the callback with the detected direction\n        if (direction && onHeadMovement) {\n          onHeadMovement(direction);\n        }\n      }\n    } catch (error) {\n      console.error('Error during face detection:', error);\n    }\n\n    // Continue detection loop\n    requestRef.current = requestAnimationFrame(detectFaces);\n  };\n\n  // Initialize camera and model\n  useEffect(() => {\n    if (active) {\n      tf.ready().then(() => {\n        setupCamera().then(() => {\n          loadModel();\n        });\n      });\n    }\n    return () => {\n      // Clean up resources\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n        requestRef.current = null;\n      }\n      if (streamRef.current) {\n        const tracks = streamRef.current.getTracks();\n        tracks.forEach(track => track.stop());\n        streamRef.current = null;\n      }\n    };\n  }, [active]);\n\n  // Start detection when model is loaded\n  useEffect(() => {\n    if (isModelLoaded && active) {\n      detectFaces();\n    }\n    return () => {\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n      }\n    };\n  }, [isModelLoaded, active]);\n\n  // Handle video loaded\n  const handleVideoLoaded = () => {\n    console.log('Video element is ready');\n    // You can add additional setup steps here if needed\n  };\n\n  // Reset calibration with a function that can be exposed if needed\n  const resetCalibration = () => {\n    calibrationRef.current = false;\n    console.log('Calibration reset');\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"face-detection\",\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      width: \"640\",\n      height: \"480\",\n      autoPlay: true,\n      playsInline: true,\n      muted: true,\n      onLoadedData: handleVideoLoaded,\n      style: {\n        display: 'none'\n      } // Hide the video element\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 178,\n      columnNumber: 7\n    }, this), !isModelLoaded && active && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"loading-model\",\n      children: \"Loading face detection model...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 189,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 177,\n    columnNumber: 5\n  }, this);\n};\n_s(FaceDetection, \"deMK2FzgYBrmaOT4r/TqjTNTm34=\");\n_c = FaceDetection;\nexport default FaceDetection;\nvar _c;\n$RefreshReg$(_c, \"FaceDetection\");","map":{"version":3,"names":["React","useEffect","useRef","useState","tf","faceLandmarksDetection","jsxDEV","_jsxDEV","FaceDetection","onHeadMovement","active","_s","videoRef","streamRef","modelRef","requestRef","isModelLoaded","setIsModelLoaded","lastPositionRef","x","y","centerPointRef","calibrationRef","loadModel","current","load","SupportedPackages","mediapipeFacemesh","maxFaces","console","log","error","setupCamera","navigator","mediaDevices","getUserMedia","video","width","height","facingMode","srcObject","calibrate","detectFaces","readyState","requestAnimationFrame","predictions","estimateFaces","input","returnTensors","flipHorizontal","predictIrises","length","nose","annotations","noseTip","deltaX","deltaY","thresholdX","thresholdY","direction","ready","then","cancelAnimationFrame","tracks","getTracks","forEach","track","stop","handleVideoLoaded","resetCalibration","className","children","ref","autoPlay","playsInline","muted","onLoadedData","style","display","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["C:/Users/kheri/Downloads/Bitcamp/bitcamp-2025/Bitcamp25/test-voice/src/FaceDetection.js"],"sourcesContent":["import React, { useEffect, useRef, useState } from 'react';\r\nimport * as tf from '@tensorflow/tfjs';\r\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\r\n\r\nconst FaceDetection = ({ onHeadMovement, active = true }) => {\r\n  const videoRef = useRef(null);\r\n  const streamRef = useRef(null);\r\n  const modelRef = useRef(null);\r\n  const requestRef = useRef(null);\r\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\r\n  const lastPositionRef = useRef({ x: 0, y: 0 });\r\n  const centerPointRef = useRef({ x: 0, y: 0 });\r\n  const calibrationRef = useRef(false);\r\n  \r\n  // Load face detection model\r\n  const loadModel = async () => {\r\n    try {\r\n      // Load the MediaPipe Facemesh package\r\n      modelRef.current = await faceLandmarksDetection.load(\r\n        faceLandmarksDetection.SupportedPackages.mediapipeFacemesh,\r\n        { maxFaces: 1 }\r\n      );\r\n      setIsModelLoaded(true);\r\n      console.log('Face detection model loaded');\r\n    } catch (error) {\r\n      console.error('Failed to load face detection model:', error);\r\n    }\r\n  };\r\n\r\n  // Set up webcam streaming\r\n  const setupCamera = async () => {\r\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\r\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get access to the webcam\r\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\r\n        video: { width: 640, height: 480, facingMode: 'user' }\r\n      });\r\n\r\n      // Set the video source\r\n      if (videoRef.current) {\r\n        videoRef.current.srcObject = streamRef.current;\r\n      }\r\n    } catch (error) {\r\n      console.error('Failed to access webcam:', error);\r\n    }\r\n  };\r\n\r\n  const calibrate = () => {\r\n    if (lastPositionRef.current) {\r\n      centerPointRef.current = { ...lastPositionRef.current };\r\n      calibrationRef.current = true;\r\n      console.log('Calibrated face position:', centerPointRef.current);\r\n    }\r\n  };\r\n\r\n  // Detect faces and send head movement\r\n  const detectFaces = async () => {\r\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\r\n      requestRef.current = requestAnimationFrame(detectFaces);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get predictions\r\n      const predictions = await modelRef.current.estimateFaces({\r\n        input: videoRef.current,\r\n        returnTensors: false,\r\n        flipHorizontal: true,\r\n        predictIrises: false\r\n      });\r\n\r\n      if (predictions.length > 0) {\r\n        // Get nose point (middle of the face)\r\n        const nose = predictions[0].annotations.noseTip[0];\r\n        \r\n        // Store current position\r\n        lastPositionRef.current = { x: nose[0], y: nose[1] };\r\n        \r\n        // If we haven't calibrated yet, do it now\r\n        if (!calibrationRef.current) {\r\n          calibrate();\r\n          return;\r\n        }\r\n        \r\n        // Calculate difference from center (calibrated position)\r\n        const deltaX = nose[0] - centerPointRef.current.x;\r\n        const deltaY = nose[1] - centerPointRef.current.y;\r\n        \r\n        // Determine thresholds for movement (adjust these values as needed)\r\n        const thresholdX = 30;\r\n        const thresholdY = 30;\r\n        \r\n        // Determine movement direction\r\n        let direction = null;\r\n        \r\n        // Check horizontal movement (left/right)\r\n        if (deltaX < -thresholdX) {\r\n          direction = 'l'; // Left\r\n        } else if (deltaX > thresholdX) {\r\n          direction = 'r'; // Right\r\n        }\r\n        // Check vertical movement (up/down) - Y increases downward in image coordinates\r\n        else if (deltaY < -thresholdY) {\r\n          direction = 'u'; // Up\r\n        } else if (deltaY > thresholdY) {\r\n          direction = 'd'; // Down\r\n        }\r\n        \r\n        // Call the callback with the detected direction\r\n        if (direction && onHeadMovement) {\r\n          onHeadMovement(direction);\r\n        }\r\n      }\r\n    } catch (error) {\r\n      console.error('Error during face detection:', error);\r\n    }\r\n    \r\n    // Continue detection loop\r\n    requestRef.current = requestAnimationFrame(detectFaces);\r\n  };\r\n\r\n  // Initialize camera and model\r\n  useEffect(() => {\r\n    if (active) {\r\n      tf.ready().then(() => {\r\n        setupCamera().then(() => {\r\n          loadModel();\r\n        });\r\n      });\r\n    }\r\n\r\n    return () => {\r\n      // Clean up resources\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n        requestRef.current = null;\r\n      }\r\n      \r\n      if (streamRef.current) {\r\n        const tracks = streamRef.current.getTracks();\r\n        tracks.forEach(track => track.stop());\r\n        streamRef.current = null;\r\n      }\r\n    };\r\n  }, [active]);\r\n\r\n  // Start detection when model is loaded\r\n  useEffect(() => {\r\n    if (isModelLoaded && active) {\r\n      detectFaces();\r\n    }\r\n    \r\n    return () => {\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n      }\r\n    };\r\n  }, [isModelLoaded, active]);\r\n\r\n  // Handle video loaded\r\n  const handleVideoLoaded = () => {\r\n    console.log('Video element is ready');\r\n    // You can add additional setup steps here if needed\r\n  };\r\n\r\n  // Reset calibration with a function that can be exposed if needed\r\n  const resetCalibration = () => {\r\n    calibrationRef.current = false;\r\n    console.log('Calibration reset');\r\n  };\r\n\r\n  return (\r\n    <div className=\"face-detection\">\r\n      <video \r\n        ref={videoRef}\r\n        width=\"640\"\r\n        height=\"480\"\r\n        autoPlay\r\n        playsInline\r\n        muted\r\n        onLoadedData={handleVideoLoaded}\r\n        style={{ display: 'none' }} // Hide the video element\r\n      />\r\n      {!isModelLoaded && active && (\r\n        <div className=\"loading-model\">Loading face detection model...</div>\r\n      )}\r\n    </div>\r\n  );\r\n};\r\n\r\nexport default FaceDetection; "],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,QAAQ,OAAO;AAC1D,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,KAAKC,sBAAsB,MAAM,6CAA6C;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtF,MAAMC,aAAa,GAAGA,CAAC;EAAEC,cAAc;EAAEC,MAAM,GAAG;AAAK,CAAC,KAAK;EAAAC,EAAA;EAC3D,MAAMC,QAAQ,GAAGV,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMW,SAAS,GAAGX,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMY,QAAQ,GAAGZ,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMa,UAAU,GAAGb,MAAM,CAAC,IAAI,CAAC;EAC/B,MAAM,CAACc,aAAa,EAAEC,gBAAgB,CAAC,GAAGd,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAMe,eAAe,GAAGhB,MAAM,CAAC;IAAEiB,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC9C,MAAMC,cAAc,GAAGnB,MAAM,CAAC;IAAEiB,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC7C,MAAME,cAAc,GAAGpB,MAAM,CAAC,KAAK,CAAC;;EAEpC;EACA,MAAMqB,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACF;MACAT,QAAQ,CAACU,OAAO,GAAG,MAAMnB,sBAAsB,CAACoB,IAAI,CAClDpB,sBAAsB,CAACqB,iBAAiB,CAACC,iBAAiB,EAC1D;QAAEC,QAAQ,EAAE;MAAE,CAChB,CAAC;MACDX,gBAAgB,CAAC,IAAI,CAAC;MACtBY,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAC;IAC5C,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;IAC9D;EACF,CAAC;;EAED;EACA,MAAMC,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAACC,SAAS,CAACC,YAAY,IAAI,CAACD,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;MACnEN,OAAO,CAACE,KAAK,CAAC,+DAA+D,CAAC;MAC9E;IACF;IAEA,IAAI;MACF;MACAlB,SAAS,CAACW,OAAO,GAAG,MAAMS,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAC5DC,KAAK,EAAE;UAAEC,KAAK,EAAE,GAAG;UAAEC,MAAM,EAAE,GAAG;UAAEC,UAAU,EAAE;QAAO;MACvD,CAAC,CAAC;;MAEF;MACA,IAAI3B,QAAQ,CAACY,OAAO,EAAE;QACpBZ,QAAQ,CAACY,OAAO,CAACgB,SAAS,GAAG3B,SAAS,CAACW,OAAO;MAChD;IACF,CAAC,CAAC,OAAOO,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,0BAA0B,EAAEA,KAAK,CAAC;IAClD;EACF,CAAC;EAED,MAAMU,SAAS,GAAGA,CAAA,KAAM;IACtB,IAAIvB,eAAe,CAACM,OAAO,EAAE;MAC3BH,cAAc,CAACG,OAAO,GAAG;QAAE,GAAGN,eAAe,CAACM;MAAQ,CAAC;MACvDF,cAAc,CAACE,OAAO,GAAG,IAAI;MAC7BK,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAET,cAAc,CAACG,OAAO,CAAC;IAClE;EACF,CAAC;;EAED;EACA,MAAMkB,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAAC5B,QAAQ,CAACU,OAAO,IAAI,CAACZ,QAAQ,CAACY,OAAO,IAAI,CAACZ,QAAQ,CAACY,OAAO,CAACmB,UAAU,KAAK,CAAC,EAAE;MAChF5B,UAAU,CAACS,OAAO,GAAGoB,qBAAqB,CAACF,WAAW,CAAC;MACvD;IACF;IAEA,IAAI;MACF;MACA,MAAMG,WAAW,GAAG,MAAM/B,QAAQ,CAACU,OAAO,CAACsB,aAAa,CAAC;QACvDC,KAAK,EAAEnC,QAAQ,CAACY,OAAO;QACvBwB,aAAa,EAAE,KAAK;QACpBC,cAAc,EAAE,IAAI;QACpBC,aAAa,EAAE;MACjB,CAAC,CAAC;MAEF,IAAIL,WAAW,CAACM,MAAM,GAAG,CAAC,EAAE;QAC1B;QACA,MAAMC,IAAI,GAAGP,WAAW,CAAC,CAAC,CAAC,CAACQ,WAAW,CAACC,OAAO,CAAC,CAAC,CAAC;;QAElD;QACApC,eAAe,CAACM,OAAO,GAAG;UAAEL,CAAC,EAAEiC,IAAI,CAAC,CAAC,CAAC;UAAEhC,CAAC,EAAEgC,IAAI,CAAC,CAAC;QAAE,CAAC;;QAEpD;QACA,IAAI,CAAC9B,cAAc,CAACE,OAAO,EAAE;UAC3BiB,SAAS,CAAC,CAAC;UACX;QACF;;QAEA;QACA,MAAMc,MAAM,GAAGH,IAAI,CAAC,CAAC,CAAC,GAAG/B,cAAc,CAACG,OAAO,CAACL,CAAC;QACjD,MAAMqC,MAAM,GAAGJ,IAAI,CAAC,CAAC,CAAC,GAAG/B,cAAc,CAACG,OAAO,CAACJ,CAAC;;QAEjD;QACA,MAAMqC,UAAU,GAAG,EAAE;QACrB,MAAMC,UAAU,GAAG,EAAE;;QAErB;QACA,IAAIC,SAAS,GAAG,IAAI;;QAEpB;QACA,IAAIJ,MAAM,GAAG,CAACE,UAAU,EAAE;UACxBE,SAAS,GAAG,GAAG,CAAC,CAAC;QACnB,CAAC,MAAM,IAAIJ,MAAM,GAAGE,UAAU,EAAE;UAC9BE,SAAS,GAAG,GAAG,CAAC,CAAC;QACnB;QACA;QAAA,KACK,IAAIH,MAAM,GAAG,CAACE,UAAU,EAAE;UAC7BC,SAAS,GAAG,GAAG,CAAC,CAAC;QACnB,CAAC,MAAM,IAAIH,MAAM,GAAGE,UAAU,EAAE;UAC9BC,SAAS,GAAG,GAAG,CAAC,CAAC;QACnB;;QAEA;QACA,IAAIA,SAAS,IAAIlD,cAAc,EAAE;UAC/BA,cAAc,CAACkD,SAAS,CAAC;QAC3B;MACF;IACF,CAAC,CAAC,OAAO5B,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;IACtD;;IAEA;IACAhB,UAAU,CAACS,OAAO,GAAGoB,qBAAqB,CAACF,WAAW,CAAC;EACzD,CAAC;;EAED;EACAzC,SAAS,CAAC,MAAM;IACd,IAAIS,MAAM,EAAE;MACVN,EAAE,CAACwD,KAAK,CAAC,CAAC,CAACC,IAAI,CAAC,MAAM;QACpB7B,WAAW,CAAC,CAAC,CAAC6B,IAAI,CAAC,MAAM;UACvBtC,SAAS,CAAC,CAAC;QACb,CAAC,CAAC;MACJ,CAAC,CAAC;IACJ;IAEA,OAAO,MAAM;MACX;MACA,IAAIR,UAAU,CAACS,OAAO,EAAE;QACtBsC,oBAAoB,CAAC/C,UAAU,CAACS,OAAO,CAAC;QACxCT,UAAU,CAACS,OAAO,GAAG,IAAI;MAC3B;MAEA,IAAIX,SAAS,CAACW,OAAO,EAAE;QACrB,MAAMuC,MAAM,GAAGlD,SAAS,CAACW,OAAO,CAACwC,SAAS,CAAC,CAAC;QAC5CD,MAAM,CAACE,OAAO,CAACC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QACrCtD,SAAS,CAACW,OAAO,GAAG,IAAI;MAC1B;IACF,CAAC;EACH,CAAC,EAAE,CAACd,MAAM,CAAC,CAAC;;EAEZ;EACAT,SAAS,CAAC,MAAM;IACd,IAAIe,aAAa,IAAIN,MAAM,EAAE;MAC3BgC,WAAW,CAAC,CAAC;IACf;IAEA,OAAO,MAAM;MACX,IAAI3B,UAAU,CAACS,OAAO,EAAE;QACtBsC,oBAAoB,CAAC/C,UAAU,CAACS,OAAO,CAAC;MAC1C;IACF,CAAC;EACH,CAAC,EAAE,CAACR,aAAa,EAAEN,MAAM,CAAC,CAAC;;EAE3B;EACA,MAAM0D,iBAAiB,GAAGA,CAAA,KAAM;IAC9BvC,OAAO,CAACC,GAAG,CAAC,wBAAwB,CAAC;IACrC;EACF,CAAC;;EAED;EACA,MAAMuC,gBAAgB,GAAGA,CAAA,KAAM;IAC7B/C,cAAc,CAACE,OAAO,GAAG,KAAK;IAC9BK,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;EAClC,CAAC;EAED,oBACEvB,OAAA;IAAK+D,SAAS,EAAC,gBAAgB;IAAAC,QAAA,gBAC7BhE,OAAA;MACEiE,GAAG,EAAE5D,QAAS;MACdyB,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZmC,QAAQ;MACRC,WAAW;MACXC,KAAK;MACLC,YAAY,EAAER,iBAAkB;MAChCS,KAAK,EAAE;QAAEC,OAAO,EAAE;MAAO,CAAE,CAAC;IAAA;MAAAC,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7B,CAAC,EACD,CAAClE,aAAa,IAAIN,MAAM,iBACvBH,OAAA;MAAK+D,SAAS,EAAC,eAAe;MAAAC,QAAA,EAAC;IAA+B;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CACpE;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC;AAACvE,EAAA,CA5LIH,aAAa;AAAA2E,EAAA,GAAb3E,aAAa;AA8LnB,eAAeA,aAAa;AAAC,IAAA2E,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}