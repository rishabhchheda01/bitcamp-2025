{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\kheri\\\\Downloads\\\\Bitcamp\\\\bitcamp-2025\\\\Bitcamp25\\\\test-voice\\\\src\\\\FaceDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';\nimport * as tf from '@tensorflow/tfjs';\nimport '@tensorflow/tfjs-backend-webgl';\nimport '@tensorflow/tfjs-backend-wasm';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\n\n// Initialize TensorFlow with the appropriate backend\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst initializeTF = async () => {\n  // Try to use WebGL first for better performance, fallback to WASM\n  try {\n    await tf.setBackend('webgl');\n    console.log('Using WebGL backend for TensorFlow.js');\n  } catch (e) {\n    try {\n      await tf.setBackend('wasm');\n      console.log('Using WASM backend for TensorFlow.js');\n    } catch (e) {\n      console.error('Failed to initialize TensorFlow backend:', e);\n    }\n  }\n};\nconst FaceDetection = /*#__PURE__*/_s(/*#__PURE__*/forwardRef(_c = _s(({\n  onHeadMovement,\n  active = true,\n  showDebug = false\n}, ref) => {\n  _s();\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const streamRef = useRef(null);\n  const modelRef = useRef(null);\n  const requestRef = useRef(null);\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\n  const lastPositionRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const centerPointRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const calibrationRef = useRef(false);\n  const [faceDetected, setFaceDetected] = useState(false);\n\n  // Expose functions to parent component\n  useImperativeHandle(ref, () => ({\n    calibrate: () => {\n      calibrate();\n    },\n    isCalibrated: () => {\n      return calibrationRef.current;\n    },\n    isFaceDetected: () => {\n      return faceDetected;\n    }\n  }));\n\n  // Load face detection model\n  const loadModel = async () => {\n    try {\n      // Try to load the MediaPipe Facemesh package first\n      try {\n        modelRef.current = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, {\n          runtime: 'mediapipe',\n          refineLandmarks: false,\n          maxFaces: 1\n        });\n        console.log('Face detection model loaded: MediaPipeFaceMesh');\n      } catch (e) {\n        console.warn('Failed to load MediaPipeFaceMesh, falling back to BlazeFace:', e);\n        // Fallback to the simpler BlazeFace model if MediaPipe fails\n        modelRef.current = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.BlazeFace, {\n          runtime: 'tfjs',\n          maxFaces: 1\n        });\n        console.log('Face detection model loaded: BlazeFace (fallback)');\n      }\n      setIsModelLoaded(true);\n    } catch (error) {\n      console.error('Failed to load any face detection model:', error);\n    }\n  };\n\n  // Set up webcam streaming\n  const setupCamera = async () => {\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\n      return;\n    }\n    try {\n      // Get access to the webcam\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\n        video: {\n          width: 640,\n          height: 480,\n          facingMode: 'user'\n        }\n      });\n\n      // Set the video source\n      if (videoRef.current) {\n        videoRef.current.srcObject = streamRef.current;\n      }\n    } catch (error) {\n      console.error('Failed to access webcam:', error);\n    }\n  };\n  const calibrate = () => {\n    if (lastPositionRef.current) {\n      centerPointRef.current = {\n        ...lastPositionRef.current\n      };\n      calibrationRef.current = true;\n      console.log('Calibrated face position:', centerPointRef.current);\n    }\n  };\n\n  // Draw facial landmarks for debugging\n  const drawFacialLandmarks = (predictions, ctx) => {\n    if (!ctx || !predictions || predictions.length === 0) return;\n\n    // Clear the canvas\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n\n    // Draw each prediction\n    predictions.forEach(prediction => {\n      // Draw facial keypoints\n      if (prediction.keypoints) {\n        for (let i = 0; i < prediction.keypoints.length; i++) {\n          const keypoint = prediction.keypoints[i];\n\n          // Draw keypoint\n          ctx.beginPath();\n          ctx.arc(keypoint.x, keypoint.y, 1, 0, 2 * Math.PI);\n          ctx.fillStyle = 'aqua';\n          ctx.fill();\n        }\n      }\n\n      // Find nose point based on model type\n      let nose;\n\n      // MediaPipeFaceMesh has keypoints with 'name' property\n      if (prediction.keypoints && prediction.keypoints.length > 0) {\n        if (prediction.keypoints[0].name) {\n          nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\n        }\n        // For BlazeFace\n        else if (prediction.keypoints.length >= 5) {\n          // In BlazeFace, keypoint 4 is approximately the nose\n          nose = prediction.keypoints[4];\n        }\n      }\n      if (nose) {\n        // Draw the nose point in a different color\n        ctx.beginPath();\n        ctx.arc(nose.x, nose.y, 5, 0, 2 * Math.PI);\n        ctx.fillStyle = 'green';\n        ctx.fill();\n\n        // Draw a line from the center calibration point to current nose position\n        if (calibrationRef.current) {\n          ctx.beginPath();\n          ctx.moveTo(centerPointRef.current.x, centerPointRef.current.y);\n          ctx.lineTo(nose.x, nose.y);\n          ctx.strokeStyle = 'white';\n          ctx.lineWidth = 2;\n          ctx.stroke();\n\n          // Draw the center calibration point\n          ctx.beginPath();\n          ctx.arc(centerPointRef.current.x, centerPointRef.current.y, 5, 0, 2 * Math.PI);\n          ctx.fillStyle = 'red';\n          ctx.fill();\n        }\n      }\n    });\n  };\n\n  // Detect faces and send head movement\n  const detectFaces = async () => {\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\n      requestRef.current = requestAnimationFrame(detectFaces);\n      return;\n    }\n    try {\n      // Get predictions using the updated API\n      const predictions = await modelRef.current.estimateFaces(videoRef.current, {\n        flipHorizontal: true\n      });\n\n      // Update face detected state\n      setFaceDetected(predictions.length > 0);\n\n      // Draw landmarks if debug is enabled\n      if (showDebug && canvasRef.current) {\n        const ctx = canvasRef.current.getContext('2d');\n        drawFacialLandmarks(predictions, ctx);\n      }\n      if (predictions.length > 0) {\n        const prediction = predictions[0];\n        let nose;\n\n        // Extract nose point based on model type\n        // MediaPipeFaceMesh has keypoints with 'name' property\n        // BlazeFace has keypoints for the whole face with specific indices\n        if (prediction.keypoints && prediction.keypoints.length > 0) {\n          // For MediaPipeFaceMesh\n          if (prediction.keypoints[0].name) {\n            nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\n          }\n          // For BlazeFace\n          else if (prediction.keypoints.length >= 5) {\n            // In BlazeFace, keypoint 4 is approximately the nose\n            nose = prediction.keypoints[4];\n          }\n        }\n        if (nose) {\n          // Store current position\n          lastPositionRef.current = {\n            x: nose.x,\n            y: nose.y\n          };\n\n          // If we haven't calibrated yet, do it now\n          if (!calibrationRef.current) {\n            calibrate();\n            return;\n          }\n\n          // Calculate difference from center (calibrated position)\n          const deltaX = nose.x - centerPointRef.current.x;\n          const deltaY = nose.y - centerPointRef.current.y;\n\n          // Determine thresholds for movement (adjust these values as needed)\n          const thresholdX = 30;\n          const thresholdY = 30;\n\n          // Determine movement direction\n          let direction = null;\n\n          // Check horizontal movement (left/right)\n          if (deltaX < -thresholdX) {\n            direction = 'l'; // Left\n          } else if (deltaX > thresholdX) {\n            direction = 'r'; // Right\n          }\n          // Check vertical movement (up/down) - Y increases downward in image coordinates\n          else if (deltaY < -thresholdY) {\n            direction = 'u'; // Up\n          } else if (deltaY > thresholdY) {\n            direction = 'd'; // Down\n          }\n\n          // Call the callback with the detected direction\n          if (direction && onHeadMovement) {\n            onHeadMovement(direction);\n          }\n        }\n      }\n    } catch (error) {\n      console.error('Error during face detection:', error);\n    }\n\n    // Continue detection loop\n    requestRef.current = requestAnimationFrame(detectFaces);\n  };\n\n  // Initialize camera and model\n  useEffect(() => {\n    if (active) {\n      initializeTF().then(() => {\n        setupCamera().then(() => {\n          loadModel();\n        });\n      });\n    }\n    return () => {\n      // Clean up resources\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n        requestRef.current = null;\n      }\n      if (streamRef.current) {\n        const tracks = streamRef.current.getTracks();\n        tracks.forEach(track => track.stop());\n        streamRef.current = null;\n      }\n    };\n  }, [active]);\n\n  // Start detection when model is loaded\n  useEffect(() => {\n    if (isModelLoaded && active) {\n      detectFaces();\n    }\n    return () => {\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n      }\n    };\n  }, [isModelLoaded, active, showDebug]);\n\n  // Handle video loaded\n  const handleVideoLoaded = () => {\n    console.log('Video element is ready');\n\n    // Set canvas dimensions to match video\n    if (canvasRef.current && videoRef.current) {\n      canvasRef.current.width = videoRef.current.videoWidth;\n      canvasRef.current.height = videoRef.current.videoHeight;\n    }\n  };\n\n  // Reset calibration with a function that can be exposed if needed\n  const resetCalibration = () => {\n    calibrationRef.current = false;\n    console.log('Calibration reset');\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: `face-detection ${showDebug ? 'debug-mode' : ''}`,\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      width: \"320\",\n      height: \"240\",\n      autoPlay: true,\n      playsInline: true,\n      muted: true,\n      onLoadedData: handleVideoLoaded,\n      style: {\n        display: showDebug ? 'block' : 'none'\n      },\n      className: \"face-video\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 320,\n      columnNumber: 7\n    }, this), showDebug && /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"320\",\n      height: \"240\",\n      className: \"landmarks-canvas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 333,\n      columnNumber: 9\n    }, this), !isModelLoaded && active && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"loading-model\",\n      children: \"Loading face detection model...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 342,\n      columnNumber: 9\n    }, this), faceDetected && active && !showDebug && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"face-detection-status\",\n      children: [\"Face \", calibrationRef.current ? 'Tracked' : 'Detected']\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 346,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 319,\n    columnNumber: 5\n  }, this);\n}, \"qWFLgGl2VifbDxvDsfBbJhvelBw=\")), \"qWFLgGl2VifbDxvDsfBbJhvelBw=\");\n_c2 = FaceDetection;\nexport default FaceDetection;\nvar _c, _c2;\n$RefreshReg$(_c, \"FaceDetection$forwardRef\");\n$RefreshReg$(_c2, \"FaceDetection\");","map":{"version":3,"names":["React","useEffect","useRef","useState","useImperativeHandle","forwardRef","tf","faceLandmarksDetection","jsxDEV","_jsxDEV","initializeTF","setBackend","console","log","e","error","FaceDetection","_s","_c","onHeadMovement","active","showDebug","ref","videoRef","canvasRef","streamRef","modelRef","requestRef","isModelLoaded","setIsModelLoaded","lastPositionRef","x","y","centerPointRef","calibrationRef","faceDetected","setFaceDetected","calibrate","isCalibrated","current","isFaceDetected","loadModel","createDetector","SupportedModels","MediaPipeFaceMesh","runtime","refineLandmarks","maxFaces","warn","BlazeFace","setupCamera","navigator","mediaDevices","getUserMedia","video","width","height","facingMode","srcObject","drawFacialLandmarks","predictions","ctx","length","clearRect","canvas","forEach","prediction","keypoints","i","keypoint","beginPath","arc","Math","PI","fillStyle","fill","nose","name","find","kp","moveTo","lineTo","strokeStyle","lineWidth","stroke","detectFaces","readyState","requestAnimationFrame","estimateFaces","flipHorizontal","getContext","deltaX","deltaY","thresholdX","thresholdY","direction","then","cancelAnimationFrame","tracks","getTracks","track","stop","handleVideoLoaded","videoWidth","videoHeight","resetCalibration","className","children","autoPlay","playsInline","muted","onLoadedData","style","display","fileName","_jsxFileName","lineNumber","columnNumber","_c2","$RefreshReg$"],"sources":["C:/Users/kheri/Downloads/Bitcamp/bitcamp-2025/Bitcamp25/test-voice/src/FaceDetection.js"],"sourcesContent":["import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';\r\nimport * as tf from '@tensorflow/tfjs';\r\nimport '@tensorflow/tfjs-backend-webgl';\r\nimport '@tensorflow/tfjs-backend-wasm';\r\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\r\n\r\n// Initialize TensorFlow with the appropriate backend\r\nconst initializeTF = async () => {\r\n  // Try to use WebGL first for better performance, fallback to WASM\r\n  try {\r\n    await tf.setBackend('webgl');\r\n    console.log('Using WebGL backend for TensorFlow.js');\r\n  } catch (e) {\r\n    try {\r\n      await tf.setBackend('wasm');\r\n      console.log('Using WASM backend for TensorFlow.js');\r\n    } catch (e) {\r\n      console.error('Failed to initialize TensorFlow backend:', e);\r\n    }\r\n  }\r\n};\r\n\r\nconst FaceDetection = forwardRef(({ onHeadMovement, active = true, showDebug = false }, ref) => {\r\n  const videoRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n  const streamRef = useRef(null);\r\n  const modelRef = useRef(null);\r\n  const requestRef = useRef(null);\r\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\r\n  const lastPositionRef = useRef({ x: 0, y: 0 });\r\n  const centerPointRef = useRef({ x: 0, y: 0 });\r\n  const calibrationRef = useRef(false);\r\n  const [faceDetected, setFaceDetected] = useState(false);\r\n  \r\n  // Expose functions to parent component\r\n  useImperativeHandle(ref, () => ({\r\n    calibrate: () => {\r\n      calibrate();\r\n    },\r\n    isCalibrated: () => {\r\n      return calibrationRef.current;\r\n    },\r\n    isFaceDetected: () => {\r\n      return faceDetected;\r\n    }\r\n  }));\r\n  \r\n  // Load face detection model\r\n  const loadModel = async () => {\r\n    try {\r\n      // Try to load the MediaPipe Facemesh package first\r\n      try {\r\n        modelRef.current = await faceLandmarksDetection.createDetector(\r\n          faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,\r\n          {\r\n            runtime: 'mediapipe',\r\n            refineLandmarks: false,\r\n            maxFaces: 1\r\n          }\r\n        );\r\n        console.log('Face detection model loaded: MediaPipeFaceMesh');\r\n      } catch (e) {\r\n        console.warn('Failed to load MediaPipeFaceMesh, falling back to BlazeFace:', e);\r\n        // Fallback to the simpler BlazeFace model if MediaPipe fails\r\n        modelRef.current = await faceLandmarksDetection.createDetector(\r\n          faceLandmarksDetection.SupportedModels.BlazeFace,\r\n          {\r\n            runtime: 'tfjs',\r\n            maxFaces: 1\r\n          }\r\n        );\r\n        console.log('Face detection model loaded: BlazeFace (fallback)');\r\n      }\r\n      \r\n      setIsModelLoaded(true);\r\n    } catch (error) {\r\n      console.error('Failed to load any face detection model:', error);\r\n    }\r\n  };\r\n\r\n  // Set up webcam streaming\r\n  const setupCamera = async () => {\r\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\r\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get access to the webcam\r\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\r\n        video: { width: 640, height: 480, facingMode: 'user' }\r\n      });\r\n\r\n      // Set the video source\r\n      if (videoRef.current) {\r\n        videoRef.current.srcObject = streamRef.current;\r\n      }\r\n    } catch (error) {\r\n      console.error('Failed to access webcam:', error);\r\n    }\r\n  };\r\n\r\n  const calibrate = () => {\r\n    if (lastPositionRef.current) {\r\n      centerPointRef.current = { ...lastPositionRef.current };\r\n      calibrationRef.current = true;\r\n      console.log('Calibrated face position:', centerPointRef.current);\r\n    }\r\n  };\r\n\r\n  // Draw facial landmarks for debugging\r\n  const drawFacialLandmarks = (predictions, ctx) => {\r\n    if (!ctx || !predictions || predictions.length === 0) return;\r\n    \r\n    // Clear the canvas\r\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\r\n    \r\n    // Draw each prediction\r\n    predictions.forEach(prediction => {\r\n      // Draw facial keypoints\r\n      if (prediction.keypoints) {\r\n        for (let i = 0; i < prediction.keypoints.length; i++) {\r\n          const keypoint = prediction.keypoints[i];\r\n          \r\n          // Draw keypoint\r\n          ctx.beginPath();\r\n          ctx.arc(keypoint.x, keypoint.y, 1, 0, 2 * Math.PI);\r\n          ctx.fillStyle = 'aqua';\r\n          ctx.fill();\r\n        }\r\n      }\r\n      \r\n      // Find nose point based on model type\r\n      let nose;\r\n      \r\n      // MediaPipeFaceMesh has keypoints with 'name' property\r\n      if (prediction.keypoints && prediction.keypoints.length > 0) {\r\n        if (prediction.keypoints[0].name) {\r\n          nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\r\n        } \r\n        // For BlazeFace\r\n        else if (prediction.keypoints.length >= 5) {\r\n          // In BlazeFace, keypoint 4 is approximately the nose\r\n          nose = prediction.keypoints[4];\r\n        }\r\n      }\r\n      \r\n      if (nose) {\r\n        // Draw the nose point in a different color\r\n        ctx.beginPath();\r\n        ctx.arc(nose.x, nose.y, 5, 0, 2 * Math.PI);\r\n        ctx.fillStyle = 'green';\r\n        ctx.fill();\r\n        \r\n        // Draw a line from the center calibration point to current nose position\r\n        if (calibrationRef.current) {\r\n          ctx.beginPath();\r\n          ctx.moveTo(centerPointRef.current.x, centerPointRef.current.y);\r\n          ctx.lineTo(nose.x, nose.y);\r\n          ctx.strokeStyle = 'white';\r\n          ctx.lineWidth = 2;\r\n          ctx.stroke();\r\n          \r\n          // Draw the center calibration point\r\n          ctx.beginPath();\r\n          ctx.arc(centerPointRef.current.x, centerPointRef.current.y, 5, 0, 2 * Math.PI);\r\n          ctx.fillStyle = 'red';\r\n          ctx.fill();\r\n        }\r\n      }\r\n    });\r\n  };\r\n\r\n  // Detect faces and send head movement\r\n  const detectFaces = async () => {\r\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\r\n      requestRef.current = requestAnimationFrame(detectFaces);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get predictions using the updated API\r\n      const predictions = await modelRef.current.estimateFaces(videoRef.current, {\r\n        flipHorizontal: true\r\n      });\r\n\r\n      // Update face detected state\r\n      setFaceDetected(predictions.length > 0);\r\n      \r\n      // Draw landmarks if debug is enabled\r\n      if (showDebug && canvasRef.current) {\r\n        const ctx = canvasRef.current.getContext('2d');\r\n        drawFacialLandmarks(predictions, ctx);\r\n      }\r\n\r\n      if (predictions.length > 0) {\r\n        const prediction = predictions[0];\r\n        let nose;\r\n        \r\n        // Extract nose point based on model type\r\n        // MediaPipeFaceMesh has keypoints with 'name' property\r\n        // BlazeFace has keypoints for the whole face with specific indices\r\n        if (prediction.keypoints && prediction.keypoints.length > 0) {\r\n          // For MediaPipeFaceMesh\r\n          if (prediction.keypoints[0].name) {\r\n            nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\r\n          } \r\n          // For BlazeFace\r\n          else if (prediction.keypoints.length >= 5) {\r\n            // In BlazeFace, keypoint 4 is approximately the nose\r\n            nose = prediction.keypoints[4];\r\n          }\r\n        }\r\n        \r\n        if (nose) {\r\n          // Store current position\r\n          lastPositionRef.current = { x: nose.x, y: nose.y };\r\n          \r\n          // If we haven't calibrated yet, do it now\r\n          if (!calibrationRef.current) {\r\n            calibrate();\r\n            return;\r\n          }\r\n          \r\n          // Calculate difference from center (calibrated position)\r\n          const deltaX = nose.x - centerPointRef.current.x;\r\n          const deltaY = nose.y - centerPointRef.current.y;\r\n          \r\n          // Determine thresholds for movement (adjust these values as needed)\r\n          const thresholdX = 30;\r\n          const thresholdY = 30;\r\n          \r\n          // Determine movement direction\r\n          let direction = null;\r\n          \r\n          // Check horizontal movement (left/right)\r\n          if (deltaX < -thresholdX) {\r\n            direction = 'l'; // Left\r\n          } else if (deltaX > thresholdX) {\r\n            direction = 'r'; // Right\r\n          }\r\n          // Check vertical movement (up/down) - Y increases downward in image coordinates\r\n          else if (deltaY < -thresholdY) {\r\n            direction = 'u'; // Up\r\n          } else if (deltaY > thresholdY) {\r\n            direction = 'd'; // Down\r\n          }\r\n          \r\n          // Call the callback with the detected direction\r\n          if (direction && onHeadMovement) {\r\n            onHeadMovement(direction);\r\n          }\r\n        }\r\n      }\r\n    } catch (error) {\r\n      console.error('Error during face detection:', error);\r\n    }\r\n    \r\n    // Continue detection loop\r\n    requestRef.current = requestAnimationFrame(detectFaces);\r\n  };\r\n\r\n  // Initialize camera and model\r\n  useEffect(() => {\r\n    if (active) {\r\n      initializeTF().then(() => {\r\n        setupCamera().then(() => {\r\n          loadModel();\r\n        });\r\n      });\r\n    }\r\n\r\n    return () => {\r\n      // Clean up resources\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n        requestRef.current = null;\r\n      }\r\n      \r\n      if (streamRef.current) {\r\n        const tracks = streamRef.current.getTracks();\r\n        tracks.forEach(track => track.stop());\r\n        streamRef.current = null;\r\n      }\r\n    };\r\n  }, [active]);\r\n\r\n  // Start detection when model is loaded\r\n  useEffect(() => {\r\n    if (isModelLoaded && active) {\r\n      detectFaces();\r\n    }\r\n    \r\n    return () => {\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n      }\r\n    };\r\n  }, [isModelLoaded, active, showDebug]);\r\n\r\n  // Handle video loaded\r\n  const handleVideoLoaded = () => {\r\n    console.log('Video element is ready');\r\n    \r\n    // Set canvas dimensions to match video\r\n    if (canvasRef.current && videoRef.current) {\r\n      canvasRef.current.width = videoRef.current.videoWidth;\r\n      canvasRef.current.height = videoRef.current.videoHeight;\r\n    }\r\n  };\r\n\r\n  // Reset calibration with a function that can be exposed if needed\r\n  const resetCalibration = () => {\r\n    calibrationRef.current = false;\r\n    console.log('Calibration reset');\r\n  };\r\n\r\n  return (\r\n    <div className={`face-detection ${showDebug ? 'debug-mode' : ''}`}>\r\n      <video \r\n        ref={videoRef}\r\n        width=\"320\"\r\n        height=\"240\"\r\n        autoPlay\r\n        playsInline\r\n        muted\r\n        onLoadedData={handleVideoLoaded}\r\n        style={{ display: showDebug ? 'block' : 'none' }}\r\n        className=\"face-video\"\r\n      />\r\n      \r\n      {showDebug && (\r\n        <canvas \r\n          ref={canvasRef}\r\n          width=\"320\"\r\n          height=\"240\"\r\n          className=\"landmarks-canvas\"\r\n        />\r\n      )}\r\n      \r\n      {!isModelLoaded && active && (\r\n        <div className=\"loading-model\">Loading face detection model...</div>\r\n      )}\r\n      \r\n      {faceDetected && active && !showDebug && (\r\n        <div className=\"face-detection-status\">\r\n          Face {calibrationRef.current ? 'Tracked' : 'Detected'}\r\n        </div>\r\n      )}\r\n    </div>\r\n  );\r\n});\r\n\r\nexport default FaceDetection; "],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,EAAEC,mBAAmB,EAAEC,UAAU,QAAQ,OAAO;AAC3F,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,gCAAgC;AACvC,OAAO,+BAA+B;AACtC,OAAO,KAAKC,sBAAsB,MAAM,6CAA6C;;AAErF;AAAA,SAAAC,MAAA,IAAAC,OAAA;AACA,MAAMC,YAAY,GAAG,MAAAA,CAAA,KAAY;EAC/B;EACA,IAAI;IACF,MAAMJ,EAAE,CAACK,UAAU,CAAC,OAAO,CAAC;IAC5BC,OAAO,CAACC,GAAG,CAAC,uCAAuC,CAAC;EACtD,CAAC,CAAC,OAAOC,CAAC,EAAE;IACV,IAAI;MACF,MAAMR,EAAE,CAACK,UAAU,CAAC,MAAM,CAAC;MAC3BC,OAAO,CAACC,GAAG,CAAC,sCAAsC,CAAC;IACrD,CAAC,CAAC,OAAOC,CAAC,EAAE;MACVF,OAAO,CAACG,KAAK,CAAC,0CAA0C,EAAED,CAAC,CAAC;IAC9D;EACF;AACF,CAAC;AAED,MAAME,aAAa,gBAAAC,EAAA,cAAGZ,UAAU,CAAAa,EAAA,GAAAD,EAAA,CAAC,CAAC;EAAEE,cAAc;EAAEC,MAAM,GAAG,IAAI;EAAEC,SAAS,GAAG;AAAM,CAAC,EAAEC,GAAG,KAAK;EAAAL,EAAA;EAC9F,MAAMM,QAAQ,GAAGrB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMsB,SAAS,GAAGtB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMuB,SAAS,GAAGvB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMwB,QAAQ,GAAGxB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMyB,UAAU,GAAGzB,MAAM,CAAC,IAAI,CAAC;EAC/B,MAAM,CAAC0B,aAAa,EAAEC,gBAAgB,CAAC,GAAG1B,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAM2B,eAAe,GAAG5B,MAAM,CAAC;IAAE6B,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC9C,MAAMC,cAAc,GAAG/B,MAAM,CAAC;IAAE6B,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC7C,MAAME,cAAc,GAAGhC,MAAM,CAAC,KAAK,CAAC;EACpC,MAAM,CAACiC,YAAY,EAAEC,eAAe,CAAC,GAAGjC,QAAQ,CAAC,KAAK,CAAC;;EAEvD;EACAC,mBAAmB,CAACkB,GAAG,EAAE,OAAO;IAC9Be,SAAS,EAAEA,CAAA,KAAM;MACfA,SAAS,CAAC,CAAC;IACb,CAAC;IACDC,YAAY,EAAEA,CAAA,KAAM;MAClB,OAAOJ,cAAc,CAACK,OAAO;IAC/B,CAAC;IACDC,cAAc,EAAEA,CAAA,KAAM;MACpB,OAAOL,YAAY;IACrB;EACF,CAAC,CAAC,CAAC;;EAEH;EACA,MAAMM,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACF;MACA,IAAI;QACFf,QAAQ,CAACa,OAAO,GAAG,MAAMhC,sBAAsB,CAACmC,cAAc,CAC5DnC,sBAAsB,CAACoC,eAAe,CAACC,iBAAiB,EACxD;UACEC,OAAO,EAAE,WAAW;UACpBC,eAAe,EAAE,KAAK;UACtBC,QAAQ,EAAE;QACZ,CACF,CAAC;QACDnC,OAAO,CAACC,GAAG,CAAC,gDAAgD,CAAC;MAC/D,CAAC,CAAC,OAAOC,CAAC,EAAE;QACVF,OAAO,CAACoC,IAAI,CAAC,8DAA8D,EAAElC,CAAC,CAAC;QAC/E;QACAY,QAAQ,CAACa,OAAO,GAAG,MAAMhC,sBAAsB,CAACmC,cAAc,CAC5DnC,sBAAsB,CAACoC,eAAe,CAACM,SAAS,EAChD;UACEJ,OAAO,EAAE,MAAM;UACfE,QAAQ,EAAE;QACZ,CACF,CAAC;QACDnC,OAAO,CAACC,GAAG,CAAC,mDAAmD,CAAC;MAClE;MAEAgB,gBAAgB,CAAC,IAAI,CAAC;IACxB,CAAC,CAAC,OAAOd,KAAK,EAAE;MACdH,OAAO,CAACG,KAAK,CAAC,0CAA0C,EAAEA,KAAK,CAAC;IAClE;EACF,CAAC;;EAED;EACA,MAAMmC,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAACC,SAAS,CAACC,YAAY,IAAI,CAACD,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;MACnEzC,OAAO,CAACG,KAAK,CAAC,+DAA+D,CAAC;MAC9E;IACF;IAEA,IAAI;MACF;MACAU,SAAS,CAACc,OAAO,GAAG,MAAMY,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAC5DC,KAAK,EAAE;UAAEC,KAAK,EAAE,GAAG;UAAEC,MAAM,EAAE,GAAG;UAAEC,UAAU,EAAE;QAAO;MACvD,CAAC,CAAC;;MAEF;MACA,IAAIlC,QAAQ,CAACgB,OAAO,EAAE;QACpBhB,QAAQ,CAACgB,OAAO,CAACmB,SAAS,GAAGjC,SAAS,CAACc,OAAO;MAChD;IACF,CAAC,CAAC,OAAOxB,KAAK,EAAE;MACdH,OAAO,CAACG,KAAK,CAAC,0BAA0B,EAAEA,KAAK,CAAC;IAClD;EACF,CAAC;EAED,MAAMsB,SAAS,GAAGA,CAAA,KAAM;IACtB,IAAIP,eAAe,CAACS,OAAO,EAAE;MAC3BN,cAAc,CAACM,OAAO,GAAG;QAAE,GAAGT,eAAe,CAACS;MAAQ,CAAC;MACvDL,cAAc,CAACK,OAAO,GAAG,IAAI;MAC7B3B,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEoB,cAAc,CAACM,OAAO,CAAC;IAClE;EACF,CAAC;;EAED;EACA,MAAMoB,mBAAmB,GAAGA,CAACC,WAAW,EAAEC,GAAG,KAAK;IAChD,IAAI,CAACA,GAAG,IAAI,CAACD,WAAW,IAAIA,WAAW,CAACE,MAAM,KAAK,CAAC,EAAE;;IAEtD;IACAD,GAAG,CAACE,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEF,GAAG,CAACG,MAAM,CAACT,KAAK,EAAEM,GAAG,CAACG,MAAM,CAACR,MAAM,CAAC;;IAExD;IACAI,WAAW,CAACK,OAAO,CAACC,UAAU,IAAI;MAChC;MACA,IAAIA,UAAU,CAACC,SAAS,EAAE;QACxB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,UAAU,CAACC,SAAS,CAACL,MAAM,EAAEM,CAAC,EAAE,EAAE;UACpD,MAAMC,QAAQ,GAAGH,UAAU,CAACC,SAAS,CAACC,CAAC,CAAC;;UAExC;UACAP,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACU,GAAG,CAACF,QAAQ,CAACtC,CAAC,EAAEsC,QAAQ,CAACrC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGwC,IAAI,CAACC,EAAE,CAAC;UAClDZ,GAAG,CAACa,SAAS,GAAG,MAAM;UACtBb,GAAG,CAACc,IAAI,CAAC,CAAC;QACZ;MACF;;MAEA;MACA,IAAIC,IAAI;;MAER;MACA,IAAIV,UAAU,CAACC,SAAS,IAAID,UAAU,CAACC,SAAS,CAACL,MAAM,GAAG,CAAC,EAAE;QAC3D,IAAII,UAAU,CAACC,SAAS,CAAC,CAAC,CAAC,CAACU,IAAI,EAAE;UAChCD,IAAI,GAAGV,UAAU,CAACC,SAAS,CAACW,IAAI,CAACC,EAAE,IAAIA,EAAE,CAACF,IAAI,KAAK,UAAU,CAAC;QAChE;QACA;QAAA,KACK,IAAIX,UAAU,CAACC,SAAS,CAACL,MAAM,IAAI,CAAC,EAAE;UACzC;UACAc,IAAI,GAAGV,UAAU,CAACC,SAAS,CAAC,CAAC,CAAC;QAChC;MACF;MAEA,IAAIS,IAAI,EAAE;QACR;QACAf,GAAG,CAACS,SAAS,CAAC,CAAC;QACfT,GAAG,CAACU,GAAG,CAACK,IAAI,CAAC7C,CAAC,EAAE6C,IAAI,CAAC5C,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGwC,IAAI,CAACC,EAAE,CAAC;QAC1CZ,GAAG,CAACa,SAAS,GAAG,OAAO;QACvBb,GAAG,CAACc,IAAI,CAAC,CAAC;;QAEV;QACA,IAAIzC,cAAc,CAACK,OAAO,EAAE;UAC1BsB,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACmB,MAAM,CAAC/C,cAAc,CAACM,OAAO,CAACR,CAAC,EAAEE,cAAc,CAACM,OAAO,CAACP,CAAC,CAAC;UAC9D6B,GAAG,CAACoB,MAAM,CAACL,IAAI,CAAC7C,CAAC,EAAE6C,IAAI,CAAC5C,CAAC,CAAC;UAC1B6B,GAAG,CAACqB,WAAW,GAAG,OAAO;UACzBrB,GAAG,CAACsB,SAAS,GAAG,CAAC;UACjBtB,GAAG,CAACuB,MAAM,CAAC,CAAC;;UAEZ;UACAvB,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACU,GAAG,CAACtC,cAAc,CAACM,OAAO,CAACR,CAAC,EAAEE,cAAc,CAACM,OAAO,CAACP,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGwC,IAAI,CAACC,EAAE,CAAC;UAC9EZ,GAAG,CAACa,SAAS,GAAG,KAAK;UACrBb,GAAG,CAACc,IAAI,CAAC,CAAC;QACZ;MACF;IACF,CAAC,CAAC;EACJ,CAAC;;EAED;EACA,MAAMU,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAAC3D,QAAQ,CAACa,OAAO,IAAI,CAAChB,QAAQ,CAACgB,OAAO,IAAI,CAAChB,QAAQ,CAACgB,OAAO,CAAC+C,UAAU,KAAK,CAAC,EAAE;MAChF3D,UAAU,CAACY,OAAO,GAAGgD,qBAAqB,CAACF,WAAW,CAAC;MACvD;IACF;IAEA,IAAI;MACF;MACA,MAAMzB,WAAW,GAAG,MAAMlC,QAAQ,CAACa,OAAO,CAACiD,aAAa,CAACjE,QAAQ,CAACgB,OAAO,EAAE;QACzEkD,cAAc,EAAE;MAClB,CAAC,CAAC;;MAEF;MACArD,eAAe,CAACwB,WAAW,CAACE,MAAM,GAAG,CAAC,CAAC;;MAEvC;MACA,IAAIzC,SAAS,IAAIG,SAAS,CAACe,OAAO,EAAE;QAClC,MAAMsB,GAAG,GAAGrC,SAAS,CAACe,OAAO,CAACmD,UAAU,CAAC,IAAI,CAAC;QAC9C/B,mBAAmB,CAACC,WAAW,EAAEC,GAAG,CAAC;MACvC;MAEA,IAAID,WAAW,CAACE,MAAM,GAAG,CAAC,EAAE;QAC1B,MAAMI,UAAU,GAAGN,WAAW,CAAC,CAAC,CAAC;QACjC,IAAIgB,IAAI;;QAER;QACA;QACA;QACA,IAAIV,UAAU,CAACC,SAAS,IAAID,UAAU,CAACC,SAAS,CAACL,MAAM,GAAG,CAAC,EAAE;UAC3D;UACA,IAAII,UAAU,CAACC,SAAS,CAAC,CAAC,CAAC,CAACU,IAAI,EAAE;YAChCD,IAAI,GAAGV,UAAU,CAACC,SAAS,CAACW,IAAI,CAACC,EAAE,IAAIA,EAAE,CAACF,IAAI,KAAK,UAAU,CAAC;UAChE;UACA;UAAA,KACK,IAAIX,UAAU,CAACC,SAAS,CAACL,MAAM,IAAI,CAAC,EAAE;YACzC;YACAc,IAAI,GAAGV,UAAU,CAACC,SAAS,CAAC,CAAC,CAAC;UAChC;QACF;QAEA,IAAIS,IAAI,EAAE;UACR;UACA9C,eAAe,CAACS,OAAO,GAAG;YAAER,CAAC,EAAE6C,IAAI,CAAC7C,CAAC;YAAEC,CAAC,EAAE4C,IAAI,CAAC5C;UAAE,CAAC;;UAElD;UACA,IAAI,CAACE,cAAc,CAACK,OAAO,EAAE;YAC3BF,SAAS,CAAC,CAAC;YACX;UACF;;UAEA;UACA,MAAMsD,MAAM,GAAGf,IAAI,CAAC7C,CAAC,GAAGE,cAAc,CAACM,OAAO,CAACR,CAAC;UAChD,MAAM6D,MAAM,GAAGhB,IAAI,CAAC5C,CAAC,GAAGC,cAAc,CAACM,OAAO,CAACP,CAAC;;UAEhD;UACA,MAAM6D,UAAU,GAAG,EAAE;UACrB,MAAMC,UAAU,GAAG,EAAE;;UAErB;UACA,IAAIC,SAAS,GAAG,IAAI;;UAEpB;UACA,IAAIJ,MAAM,GAAG,CAACE,UAAU,EAAE;YACxBE,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB,CAAC,MAAM,IAAIJ,MAAM,GAAGE,UAAU,EAAE;YAC9BE,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB;UACA;UAAA,KACK,IAAIH,MAAM,GAAG,CAACE,UAAU,EAAE;YAC7BC,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB,CAAC,MAAM,IAAIH,MAAM,GAAGE,UAAU,EAAE;YAC9BC,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB;;UAEA;UACA,IAAIA,SAAS,IAAI5E,cAAc,EAAE;YAC/BA,cAAc,CAAC4E,SAAS,CAAC;UAC3B;QACF;MACF;IACF,CAAC,CAAC,OAAOhF,KAAK,EAAE;MACdH,OAAO,CAACG,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;IACtD;;IAEA;IACAY,UAAU,CAACY,OAAO,GAAGgD,qBAAqB,CAACF,WAAW,CAAC;EACzD,CAAC;;EAED;EACApF,SAAS,CAAC,MAAM;IACd,IAAImB,MAAM,EAAE;MACVV,YAAY,CAAC,CAAC,CAACsF,IAAI,CAAC,MAAM;QACxB9C,WAAW,CAAC,CAAC,CAAC8C,IAAI,CAAC,MAAM;UACvBvD,SAAS,CAAC,CAAC;QACb,CAAC,CAAC;MACJ,CAAC,CAAC;IACJ;IAEA,OAAO,MAAM;MACX;MACA,IAAId,UAAU,CAACY,OAAO,EAAE;QACtB0D,oBAAoB,CAACtE,UAAU,CAACY,OAAO,CAAC;QACxCZ,UAAU,CAACY,OAAO,GAAG,IAAI;MAC3B;MAEA,IAAId,SAAS,CAACc,OAAO,EAAE;QACrB,MAAM2D,MAAM,GAAGzE,SAAS,CAACc,OAAO,CAAC4D,SAAS,CAAC,CAAC;QAC5CD,MAAM,CAACjC,OAAO,CAACmC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QACrC5E,SAAS,CAACc,OAAO,GAAG,IAAI;MAC1B;IACF,CAAC;EACH,CAAC,EAAE,CAACnB,MAAM,CAAC,CAAC;;EAEZ;EACAnB,SAAS,CAAC,MAAM;IACd,IAAI2B,aAAa,IAAIR,MAAM,EAAE;MAC3BiE,WAAW,CAAC,CAAC;IACf;IAEA,OAAO,MAAM;MACX,IAAI1D,UAAU,CAACY,OAAO,EAAE;QACtB0D,oBAAoB,CAACtE,UAAU,CAACY,OAAO,CAAC;MAC1C;IACF,CAAC;EACH,CAAC,EAAE,CAACX,aAAa,EAAER,MAAM,EAAEC,SAAS,CAAC,CAAC;;EAEtC;EACA,MAAMiF,iBAAiB,GAAGA,CAAA,KAAM;IAC9B1F,OAAO,CAACC,GAAG,CAAC,wBAAwB,CAAC;;IAErC;IACA,IAAIW,SAAS,CAACe,OAAO,IAAIhB,QAAQ,CAACgB,OAAO,EAAE;MACzCf,SAAS,CAACe,OAAO,CAACgB,KAAK,GAAGhC,QAAQ,CAACgB,OAAO,CAACgE,UAAU;MACrD/E,SAAS,CAACe,OAAO,CAACiB,MAAM,GAAGjC,QAAQ,CAACgB,OAAO,CAACiE,WAAW;IACzD;EACF,CAAC;;EAED;EACA,MAAMC,gBAAgB,GAAGA,CAAA,KAAM;IAC7BvE,cAAc,CAACK,OAAO,GAAG,KAAK;IAC9B3B,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;EAClC,CAAC;EAED,oBACEJ,OAAA;IAAKiG,SAAS,EAAE,kBAAkBrF,SAAS,GAAG,YAAY,GAAG,EAAE,EAAG;IAAAsF,QAAA,gBAChElG,OAAA;MACEa,GAAG,EAAEC,QAAS;MACdgC,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZoD,QAAQ;MACRC,WAAW;MACXC,KAAK;MACLC,YAAY,EAAET,iBAAkB;MAChCU,KAAK,EAAE;QAAEC,OAAO,EAAE5F,SAAS,GAAG,OAAO,GAAG;MAAO,CAAE;MACjDqF,SAAS,EAAC;IAAY;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACvB,CAAC,EAEDhG,SAAS,iBACRZ,OAAA;MACEa,GAAG,EAAEE,SAAU;MACf+B,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZkD,SAAS,EAAC;IAAkB;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7B,CACF,EAEA,CAACzF,aAAa,IAAIR,MAAM,iBACvBX,OAAA;MAAKiG,SAAS,EAAC,eAAe;MAAAC,QAAA,EAAC;IAA+B;MAAAO,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CACpE,EAEAlF,YAAY,IAAIf,MAAM,IAAI,CAACC,SAAS,iBACnCZ,OAAA;MAAKiG,SAAS,EAAC,uBAAuB;MAAAC,QAAA,GAAC,OAChC,EAACzE,cAAc,CAACK,OAAO,GAAG,SAAS,GAAG,UAAU;IAAA;MAAA2E,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAClD,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC,kCAAC;AAACC,GAAA,GAzUGtG,aAAa;AA2UnB,eAAeA,aAAa;AAAC,IAAAE,EAAA,EAAAoG,GAAA;AAAAC,YAAA,CAAArG,EAAA;AAAAqG,YAAA,CAAAD,GAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}