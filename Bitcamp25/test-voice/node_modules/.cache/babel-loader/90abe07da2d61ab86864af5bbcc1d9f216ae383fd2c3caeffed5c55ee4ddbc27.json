{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { BatchMatMul, broadcast_util, util } from '@tensorflow/tfjs-core';\nimport { reshape } from './Reshape';\nlet wasmBatchMatMul;\nfunction setup(backend) {\n  wasmBatchMatMul = backend.wasm.cwrap(BatchMatMul, null /* void */, ['number', 'array', 'number', 'number', 'array', 'number', 'number', 'number', 'number' // out_id\n  ]);\n}\nfunction batchMatMul(args) {\n  const {\n    inputs,\n    backend,\n    attrs\n  } = args;\n  const {\n    a,\n    b\n  } = inputs;\n  const {\n    transposeA,\n    transposeB\n  } = attrs;\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(`BatchMatMul for non non-float32 tensors not yet supported.`);\n  }\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n  util.assert(innerShapeA === innerShapeB, () => `Error in matMul: inner shapes (${innerShapeA}) and (` + `${innerShapeB}) of Tensors with shapes ${a.shape} and ` + `${b.shape} and transposeA=${transposeA}` + ` and transposeB=${transposeB} must match.`);\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB];\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({\n    inputs: {\n      x: a\n    },\n    backend,\n    attrs: {\n      shape: a3dShape\n    }\n  });\n  const b3d = reshape({\n    inputs: {\n      x: b\n    },\n    backend,\n    attrs: {\n      shape: b3dShape\n    }\n  });\n  const a3dId = backend.dataIdMap.get(a3d.dataId).id;\n  const b3dId = backend.dataIdMap.get(b3d.dataId).id;\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n  const out = backend.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n  const aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);\n  wasmBatchMatMul(a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes, b3d.shape.length, transposeA, transposeB, outId);\n  backend.disposeData(a3d.dataId);\n  backend.disposeData(b3d.dataId);\n  out.shape = outShape;\n  return out;\n}\nexport const batchMatMulConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: batchMatMul\n};","map":{"version":3,"names":["BatchMatMul","broadcast_util","util","reshape","wasmBatchMatMul","setup","backend","wasm","cwrap","batchMatMul","args","inputs","attrs","a","b","transposeA","transposeB","dtype","Error","aRank","shape","length","bRank","innerShapeA","innerShapeB","outerShapeA","outerShapeB","outerDimsA","slice","outerDimsB","batchDimA","sizeFromShape","batchDimB","outShapeOuterDims","assertAndGetBroadcastShape","outShape","concat","assert","a3dShape","b3dShape","a3d","x","b3d","a3dId","dataIdMap","get","dataId","id","b3dId","leftDim","rightDim","batchDim","Math","max","out","makeOutput","outId","aShapeBytes","Uint8Array","Int32Array","buffer","bShapeBytes","disposeData","batchMatMulConfig","kernelName","backendName","setupFunc","kernelFunc"],"sources":["C:\\Users\\kheri\\Downloads\\Bitcamp\\bitcamp-2025\\Bitcamp25\\tfjs-backend-wasm\\src\\kernels\\BatchMatMul.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {BatchMatMul, BatchMatMulAttrs, BatchMatMulInputs, broadcast_util, KernelConfig, KernelFunc, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {reshape} from './Reshape';\n\nlet wasmBatchMatMul: (\n    aId: number, aShape: Uint8Array, aShapeSize: number, bId: number,\n    bShape: Uint8Array, bShapeSize: number, transposeA: boolean,\n    transposeB: boolean, outId: number) => void;\n\nfunction setup(backend: BackendWasm) {\n  wasmBatchMatMul = backend.wasm.cwrap(BatchMatMul, null /* void */, [\n    'number',  // a_id\n    'array',   // a_shape\n    'number',  // a_shape.length\n    'number',  // b_id\n    'array',   // b_shape\n    'number',  // b_shape.length\n    'number',  // transpose_a\n    'number',  // transpose_b\n    'number'   // out_id\n  ]);\n}\n\nfunction batchMatMul(args: {\n  inputs: BatchMatMulInputs,\n  backend: BackendWasm,\n  attrs: BatchMatMulAttrs\n}) {\n  const {inputs, backend, attrs} = args;\n  const {a, b} = inputs;\n  const {transposeA, transposeB} = attrs;\n\n  if (a.dtype !== 'float32' || b.dtype !== 'float32') {\n    throw new Error(\n        `BatchMatMul for non non-float32 tensors not yet supported.`);\n  }\n\n  const aRank = a.shape.length;\n  const bRank = b.shape.length;\n\n  const innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  const innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n\n  const outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  const outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n\n  const outerDimsA = a.shape.slice(0, -2);\n  const outerDimsB = b.shape.slice(0, -2);\n\n  const batchDimA = util.sizeFromShape(outerDimsA);\n  const batchDimB = util.sizeFromShape(outerDimsB);\n\n  const outShapeOuterDims = broadcast_util.assertAndGetBroadcastShape(\n      a.shape.slice(0, -2), b.shape.slice(0, -2));\n  const outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n\n  util.assert(\n      innerShapeA === innerShapeB,\n      () => `Error in matMul: inner shapes (${innerShapeA}) and (` +\n          `${innerShapeB}) of Tensors with shapes ${a.shape} and ` +\n          `${b.shape} and transposeA=${transposeA}` +\n          ` and transposeB=${transposeB} must match.`);\n\n  const a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] :\n                                [batchDimA, outerShapeA, innerShapeA];\n  const b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] :\n                                [batchDimB, innerShapeB, outerShapeB];\n\n  // The rest of the implementation is designed to operate on rank-3 tensors\n  const a3d = reshape({inputs: {x: a}, backend, attrs: {shape: a3dShape}});\n  const b3d = reshape({inputs: {x: b}, backend, attrs: {shape: b3dShape}});\n\n  const a3dId = backend.dataIdMap.get(a3d.dataId).id;\n  const b3dId = backend.dataIdMap.get(b3d.dataId).id;\n\n  const leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  const rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  const batchDim = Math.max(batchDimA, batchDimB);\n\n  const out = backend.makeOutput([batchDim, leftDim, rightDim], a3d.dtype);\n  const outId = backend.dataIdMap.get(out.dataId).id;\n\n  const aShapeBytes = new Uint8Array(new Int32Array(a3d.shape).buffer);\n  const bShapeBytes = new Uint8Array(new Int32Array(b3d.shape).buffer);\n\n  wasmBatchMatMul(\n      a3dId, aShapeBytes, a3d.shape.length, b3dId, bShapeBytes,\n      b3d.shape.length, transposeA, transposeB, outId);\n\n  backend.disposeData(a3d.dataId);\n  backend.disposeData(b3d.dataId);\n\n  out.shape = outShape;\n  return out;\n}\n\nexport const batchMatMulConfig: KernelConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: batchMatMul as unknown as KernelFunc\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,WAAW,EAAuCC,cAAc,EAA4BC,IAAI,QAAO,uBAAuB;AAItI,SAAQC,OAAO,QAAO,WAAW;AAEjC,IAAIC,eAG2C;AAE/C,SAASC,KAAKA,CAACC,OAAoB;EACjCF,eAAe,GAAGE,OAAO,CAACC,IAAI,CAACC,KAAK,CAACR,WAAW,EAAE,IAAI,CAAC,YAAY,CACjE,QAAQ,EACR,OAAO,EACP,QAAQ,EACR,QAAQ,EACR,OAAO,EACP,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,CAAG;EAAA,CACZ,CAAC;AACJ;AAEA,SAASS,WAAWA,CAACC,IAIpB;EACC,MAAM;IAACC,MAAM;IAAEL,OAAO;IAAEM;EAAK,CAAC,GAAGF,IAAI;EACrC,MAAM;IAACG,CAAC;IAAEC;EAAC,CAAC,GAAGH,MAAM;EACrB,MAAM;IAACI,UAAU;IAAEC;EAAU,CAAC,GAAGJ,KAAK;EAEtC,IAAIC,CAAC,CAACI,KAAK,KAAK,SAAS,IAAIH,CAAC,CAACG,KAAK,KAAK,SAAS,EAAE;IAClD,MAAM,IAAIC,KAAK,CACX,4DAA4D,CAAC;;EAGnE,MAAMC,KAAK,GAAGN,CAAC,CAACO,KAAK,CAACC,MAAM;EAC5B,MAAMC,KAAK,GAAGR,CAAC,CAACM,KAAK,CAACC,MAAM;EAE5B,MAAME,WAAW,GAAGR,UAAU,GAAGF,CAAC,CAACO,KAAK,CAACD,KAAK,GAAG,CAAC,CAAC,GAAGN,CAAC,CAACO,KAAK,CAACD,KAAK,GAAG,CAAC,CAAC;EACxE,MAAMK,WAAW,GAAGR,UAAU,GAAGF,CAAC,CAACM,KAAK,CAACE,KAAK,GAAG,CAAC,CAAC,GAAGR,CAAC,CAACM,KAAK,CAACE,KAAK,GAAG,CAAC,CAAC;EAExE,MAAMG,WAAW,GAAGV,UAAU,GAAGF,CAAC,CAACO,KAAK,CAACD,KAAK,GAAG,CAAC,CAAC,GAAGN,CAAC,CAACO,KAAK,CAACD,KAAK,GAAG,CAAC,CAAC;EACxE,MAAMO,WAAW,GAAGV,UAAU,GAAGF,CAAC,CAACM,KAAK,CAACE,KAAK,GAAG,CAAC,CAAC,GAAGR,CAAC,CAACM,KAAK,CAACE,KAAK,GAAG,CAAC,CAAC;EAExE,MAAMK,UAAU,GAAGd,CAAC,CAACO,KAAK,CAACQ,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EACvC,MAAMC,UAAU,GAAGf,CAAC,CAACM,KAAK,CAACQ,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC;EAEvC,MAAME,SAAS,GAAG5B,IAAI,CAAC6B,aAAa,CAACJ,UAAU,CAAC;EAChD,MAAMK,SAAS,GAAG9B,IAAI,CAAC6B,aAAa,CAACF,UAAU,CAAC;EAEhD,MAAMI,iBAAiB,GAAGhC,cAAc,CAACiC,0BAA0B,CAC/DrB,CAAC,CAACO,KAAK,CAACQ,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,EAAEd,CAAC,CAACM,KAAK,CAACQ,KAAK,CAAC,CAAC,EAAE,CAAC,CAAC,CAAC,CAAC;EAC/C,MAAMO,QAAQ,GAAGF,iBAAiB,CAACG,MAAM,CAAC,CAACX,WAAW,EAAEC,WAAW,CAAC,CAAC;EAErExB,IAAI,CAACmC,MAAM,CACPd,WAAW,KAAKC,WAAW,EAC3B,MAAM,kCAAkCD,WAAW,SAAS,GACxD,GAAGC,WAAW,4BAA4BX,CAAC,CAACO,KAAK,OAAO,GACxD,GAAGN,CAAC,CAACM,KAAK,mBAAmBL,UAAU,EAAE,GACzC,mBAAmBC,UAAU,cAAc,CAAC;EAEpD,MAAMsB,QAAQ,GAAGvB,UAAU,GAAG,CAACe,SAAS,EAAEP,WAAW,EAAEE,WAAW,CAAC,GACrC,CAACK,SAAS,EAAEL,WAAW,EAAEF,WAAW,CAAC;EACnE,MAAMgB,QAAQ,GAAGvB,UAAU,GAAG,CAACgB,SAAS,EAAEN,WAAW,EAAEF,WAAW,CAAC,GACrC,CAACQ,SAAS,EAAER,WAAW,EAAEE,WAAW,CAAC;EAEnE;EACA,MAAMc,GAAG,GAAGrC,OAAO,CAAC;IAACQ,MAAM,EAAE;MAAC8B,CAAC,EAAE5B;IAAC,CAAC;IAAEP,OAAO;IAAEM,KAAK,EAAE;MAACQ,KAAK,EAAEkB;IAAQ;EAAC,CAAC,CAAC;EACxE,MAAMI,GAAG,GAAGvC,OAAO,CAAC;IAACQ,MAAM,EAAE;MAAC8B,CAAC,EAAE3B;IAAC,CAAC;IAAER,OAAO;IAAEM,KAAK,EAAE;MAACQ,KAAK,EAAEmB;IAAQ;EAAC,CAAC,CAAC;EAExE,MAAMI,KAAK,GAAGrC,OAAO,CAACsC,SAAS,CAACC,GAAG,CAACL,GAAG,CAACM,MAAM,CAAC,CAACC,EAAE;EAClD,MAAMC,KAAK,GAAG1C,OAAO,CAACsC,SAAS,CAACC,GAAG,CAACH,GAAG,CAACI,MAAM,CAAC,CAACC,EAAE;EAElD,MAAME,OAAO,GAAGlC,UAAU,GAAGyB,GAAG,CAACpB,KAAK,CAAC,CAAC,CAAC,GAAGoB,GAAG,CAACpB,KAAK,CAAC,CAAC,CAAC;EACxD,MAAM8B,QAAQ,GAAGlC,UAAU,GAAG0B,GAAG,CAACtB,KAAK,CAAC,CAAC,CAAC,GAAGsB,GAAG,CAACtB,KAAK,CAAC,CAAC,CAAC;EACzD,MAAM+B,QAAQ,GAAGC,IAAI,CAACC,GAAG,CAACvB,SAAS,EAAEE,SAAS,CAAC;EAE/C,MAAMsB,GAAG,GAAGhD,OAAO,CAACiD,UAAU,CAAC,CAACJ,QAAQ,EAAEF,OAAO,EAAEC,QAAQ,CAAC,EAAEV,GAAG,CAACvB,KAAK,CAAC;EACxE,MAAMuC,KAAK,GAAGlD,OAAO,CAACsC,SAAS,CAACC,GAAG,CAACS,GAAG,CAACR,MAAM,CAAC,CAACC,EAAE;EAElD,MAAMU,WAAW,GAAG,IAAIC,UAAU,CAAC,IAAIC,UAAU,CAACnB,GAAG,CAACpB,KAAK,CAAC,CAACwC,MAAM,CAAC;EACpE,MAAMC,WAAW,GAAG,IAAIH,UAAU,CAAC,IAAIC,UAAU,CAACjB,GAAG,CAACtB,KAAK,CAAC,CAACwC,MAAM,CAAC;EAEpExD,eAAe,CACXuC,KAAK,EAAEc,WAAW,EAAEjB,GAAG,CAACpB,KAAK,CAACC,MAAM,EAAE2B,KAAK,EAAEa,WAAW,EACxDnB,GAAG,CAACtB,KAAK,CAACC,MAAM,EAAEN,UAAU,EAAEC,UAAU,EAAEwC,KAAK,CAAC;EAEpDlD,OAAO,CAACwD,WAAW,CAACtB,GAAG,CAACM,MAAM,CAAC;EAC/BxC,OAAO,CAACwD,WAAW,CAACpB,GAAG,CAACI,MAAM,CAAC;EAE/BQ,GAAG,CAAClC,KAAK,GAAGe,QAAQ;EACpB,OAAOmB,GAAG;AACZ;AAEA,OAAO,MAAMS,iBAAiB,GAAiB;EAC7CC,UAAU,EAAEhE,WAAW;EACvBiE,WAAW,EAAE,MAAM;EACnBC,SAAS,EAAE7D,KAAK;EAChB8D,UAAU,EAAE1D;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}