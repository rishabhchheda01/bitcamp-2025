{"ast":null,"code":"/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util, Max, util } from '@tensorflow/tfjs-core';\nimport { permuteAxesAndTranspose } from './kernel_utils';\nimport { CppDType } from './types';\nlet wasmMax;\nfunction setup(backend) {\n  wasmMax = backend.wasm.cwrap(Max, null /*void*/, ['number', 'number', 'number', 'number' // out_id\n  ]);\n}\nfunction max(args) {\n  const {\n    backend,\n    inputs,\n    attrs\n  } = args;\n  const {\n    reductionIndices: axis,\n    keepDims\n  } = attrs;\n  const {\n    x\n  } = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n  const {\n    transposed,\n    axes,\n    originalAxes,\n    inputWasTransposed\n  } = permuteAxesAndTranspose(x, axis, backend);\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    input = transposed;\n    inputId = transposedId;\n  }\n  const inputRank = input.shape.length;\n  backend_util.assertAxesAreInnerMostDims('max', axes, inputRank);\n  const [outShape, reduceShape] = backend_util.computeOutAndReduceShapes(input.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n  const out = backend.makeOutput(outShape, x.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmMax(inputId, CppDType[x.dtype], reduceSize, outId);\n  }\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n  return out;\n}\nexport const maxConfig = {\n  kernelName: Max,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: max\n};","map":{"version":3,"names":["backend_util","Max","util","permuteAxesAndTranspose","CppDType","wasmMax","setup","backend","wasm","cwrap","max","args","inputs","attrs","reductionIndices","axis","keepDims","x","xId","dataIdMap","get","dataId","id","inputId","input","transposed","axes","originalAxes","inputWasTransposed","transposedId","inputRank","shape","length","assertAxesAreInnerMostDims","outShape","reduceShape","computeOutAndReduceShapes","reduceSize","sizeFromShape","out","makeOutput","dtype","outId","disposeData","newShape","expandShapeToKeepDim","maxConfig","kernelName","backendName","setupFunc","kernelFunc"],"sources":["C:\\Users\\kheri\\Downloads\\Bitcamp\\bitcamp-2025\\Bitcamp25\\tfjs-backend-wasm\\src\\kernels\\Max.ts"],"sourcesContent":["/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nimport {backend_util, KernelConfig, KernelFunc, Max, MaxAttrs, MaxInputs, TensorInfo, util} from '@tensorflow/tfjs-core';\n\nimport {BackendWasm} from '../backend_wasm';\n\nimport {permuteAxesAndTranspose} from './kernel_utils';\nimport {CppDType} from './types';\n\nlet wasmMax: (xId: number, dtype: number, reduceSize: number, outId: number) =>\n    void;\n\nfunction setup(backend: BackendWasm): void {\n  wasmMax = backend.wasm.cwrap(Max, null /*void*/, [\n    'number',  // x_id\n    'number',  // dtype\n    'number',  // reduce_size\n    'number',  // out_id\n  ]);\n}\n\nfunction max(args: {backend: BackendWasm, inputs: MaxInputs, attrs: MaxAttrs}):\n    TensorInfo {\n  const {backend, inputs, attrs} = args;\n  const {reductionIndices: axis, keepDims} = attrs;\n  const {x} = inputs;\n  const xId = backend.dataIdMap.get(x.dataId).id;\n  let inputId = xId;\n  let input = x;\n\n  const {transposed, axes, originalAxes, inputWasTransposed} =\n      permuteAxesAndTranspose(x, axis, backend);\n\n  if (inputWasTransposed) {\n    const transposedId = backend.dataIdMap.get(transposed.dataId).id;\n    input = transposed;\n    inputId = transposedId;\n  }\n\n  const inputRank = input.shape.length;\n  backend_util.assertAxesAreInnerMostDims('max', axes, inputRank);\n  const [outShape, reduceShape] =\n      backend_util.computeOutAndReduceShapes(input.shape, axes);\n  const reduceSize = util.sizeFromShape(reduceShape);\n\n  const out = backend.makeOutput(outShape, x.dtype);\n  if (util.sizeFromShape(input.shape) !== 0) {\n    const outId = backend.dataIdMap.get(out.dataId).id;\n    wasmMax(inputId, CppDType[x.dtype], reduceSize, outId);\n  }\n\n  if (inputWasTransposed) {\n    // dispose of the transposed tensor.\n    backend.disposeData(transposed.dataId);\n  }\n\n  if (keepDims) {\n    // reshape\n    const newShape = backend_util.expandShapeToKeepDim(out.shape, originalAxes);\n    out.shape = newShape;\n  }\n\n  return out;\n}\n\nexport const maxConfig: KernelConfig = {\n  kernelName: Max,\n  backendName: 'wasm',\n  setupFunc: setup,\n  kernelFunc: max as unknown as KernelFunc\n};\n"],"mappings":"AAAA;;;;;;;;;;;;;;;;AAiBA,SAAQA,YAAY,EAA4BC,GAAG,EAAmCC,IAAI,QAAO,uBAAuB;AAIxH,SAAQC,uBAAuB,QAAO,gBAAgB;AACtD,SAAQC,QAAQ,QAAO,SAAS;AAEhC,IAAIC,OACI;AAER,SAASC,KAAKA,CAACC,OAAoB;EACjCF,OAAO,GAAGE,OAAO,CAACC,IAAI,CAACC,KAAK,CAACR,GAAG,EAAE,IAAI,CAAC,UAAU,CAC/C,QAAQ,EACR,QAAQ,EACR,QAAQ,EACR,QAAQ,CAAG;EAAA,CACZ,CAAC;AACJ;AAEA,SAASS,GAAGA,CAACC,IAAgE;EAE3E,MAAM;IAACJ,OAAO;IAAEK,MAAM;IAAEC;EAAK,CAAC,GAAGF,IAAI;EACrC,MAAM;IAACG,gBAAgB,EAAEC,IAAI;IAAEC;EAAQ,CAAC,GAAGH,KAAK;EAChD,MAAM;IAACI;EAAC,CAAC,GAAGL,MAAM;EAClB,MAAMM,GAAG,GAAGX,OAAO,CAACY,SAAS,CAACC,GAAG,CAACH,CAAC,CAACI,MAAM,CAAC,CAACC,EAAE;EAC9C,IAAIC,OAAO,GAAGL,GAAG;EACjB,IAAIM,KAAK,GAAGP,CAAC;EAEb,MAAM;IAACQ,UAAU;IAAEC,IAAI;IAAEC,YAAY;IAAEC;EAAkB,CAAC,GACtDzB,uBAAuB,CAACc,CAAC,EAAEF,IAAI,EAAER,OAAO,CAAC;EAE7C,IAAIqB,kBAAkB,EAAE;IACtB,MAAMC,YAAY,GAAGtB,OAAO,CAACY,SAAS,CAACC,GAAG,CAACK,UAAU,CAACJ,MAAM,CAAC,CAACC,EAAE;IAChEE,KAAK,GAAGC,UAAU;IAClBF,OAAO,GAAGM,YAAY;;EAGxB,MAAMC,SAAS,GAAGN,KAAK,CAACO,KAAK,CAACC,MAAM;EACpChC,YAAY,CAACiC,0BAA0B,CAAC,KAAK,EAAEP,IAAI,EAAEI,SAAS,CAAC;EAC/D,MAAM,CAACI,QAAQ,EAAEC,WAAW,CAAC,GACzBnC,YAAY,CAACoC,yBAAyB,CAACZ,KAAK,CAACO,KAAK,EAAEL,IAAI,CAAC;EAC7D,MAAMW,UAAU,GAAGnC,IAAI,CAACoC,aAAa,CAACH,WAAW,CAAC;EAElD,MAAMI,GAAG,GAAGhC,OAAO,CAACiC,UAAU,CAACN,QAAQ,EAAEjB,CAAC,CAACwB,KAAK,CAAC;EACjD,IAAIvC,IAAI,CAACoC,aAAa,CAACd,KAAK,CAACO,KAAK,CAAC,KAAK,CAAC,EAAE;IACzC,MAAMW,KAAK,GAAGnC,OAAO,CAACY,SAAS,CAACC,GAAG,CAACmB,GAAG,CAAClB,MAAM,CAAC,CAACC,EAAE;IAClDjB,OAAO,CAACkB,OAAO,EAAEnB,QAAQ,CAACa,CAAC,CAACwB,KAAK,CAAC,EAAEJ,UAAU,EAAEK,KAAK,CAAC;;EAGxD,IAAId,kBAAkB,EAAE;IACtB;IACArB,OAAO,CAACoC,WAAW,CAAClB,UAAU,CAACJ,MAAM,CAAC;;EAGxC,IAAIL,QAAQ,EAAE;IACZ;IACA,MAAM4B,QAAQ,GAAG5C,YAAY,CAAC6C,oBAAoB,CAACN,GAAG,CAACR,KAAK,EAAEJ,YAAY,CAAC;IAC3EY,GAAG,CAACR,KAAK,GAAGa,QAAQ;;EAGtB,OAAOL,GAAG;AACZ;AAEA,OAAO,MAAMO,SAAS,GAAiB;EACrCC,UAAU,EAAE9C,GAAG;EACf+C,WAAW,EAAE,MAAM;EACnBC,SAAS,EAAE3C,KAAK;EAChB4C,UAAU,EAAExC;CACb","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}