{"ast":null,"code":"var _jsxFileName = \"C:\\\\Users\\\\kheri\\\\Downloads\\\\Bitcamp\\\\bitcamp-2025\\\\Bitcamp25\\\\test-voice\\\\src\\\\FaceDetection.js\",\n  _s = $RefreshSig$();\nimport React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';\nimport * as tf from '@tensorflow/tfjs';\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst FaceDetection = /*#__PURE__*/_s(/*#__PURE__*/forwardRef(_c = _s(({\n  onHeadMovement,\n  active = true,\n  showDebug = false\n}, ref) => {\n  _s();\n  const videoRef = useRef(null);\n  const canvasRef = useRef(null);\n  const streamRef = useRef(null);\n  const modelRef = useRef(null);\n  const requestRef = useRef(null);\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\n  const lastPositionRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const centerPointRef = useRef({\n    x: 0,\n    y: 0\n  });\n  const calibrationRef = useRef(false);\n  const [faceDetected, setFaceDetected] = useState(false);\n\n  // Expose functions to parent component\n  useImperativeHandle(ref, () => ({\n    calibrate: () => {\n      calibrate();\n    },\n    isCalibrated: () => {\n      return calibrationRef.current;\n    },\n    isFaceDetected: () => {\n      return faceDetected;\n    }\n  }));\n\n  // Load face detection model\n  const loadModel = async () => {\n    try {\n      // Load the MediaPipe Facemesh package using the current API\n      modelRef.current = await faceLandmarksDetection.createDetector(faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh, {\n        runtime: 'mediapipe',\n        refineLandmarks: false,\n        maxFaces: 1\n      });\n      setIsModelLoaded(true);\n      console.log('Face detection model loaded');\n    } catch (error) {\n      console.error('Failed to load face detection model:', error);\n    }\n  };\n\n  // Set up webcam streaming\n  const setupCamera = async () => {\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\n      return;\n    }\n    try {\n      // Get access to the webcam\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\n        video: {\n          width: 640,\n          height: 480,\n          facingMode: 'user'\n        }\n      });\n\n      // Set the video source\n      if (videoRef.current) {\n        videoRef.current.srcObject = streamRef.current;\n      }\n    } catch (error) {\n      console.error('Failed to access webcam:', error);\n    }\n  };\n  const calibrate = () => {\n    if (lastPositionRef.current) {\n      centerPointRef.current = {\n        ...lastPositionRef.current\n      };\n      calibrationRef.current = true;\n      console.log('Calibrated face position:', centerPointRef.current);\n    }\n  };\n\n  // Draw facial landmarks for debugging\n  const drawFacialLandmarks = (predictions, ctx) => {\n    if (!ctx || !predictions || predictions.length === 0) return;\n\n    // Clear the canvas\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\n\n    // Draw each prediction\n    predictions.forEach(prediction => {\n      // Draw facial keypoints\n      if (prediction.keypoints) {\n        for (let i = 0; i < prediction.keypoints.length; i++) {\n          const keypoint = prediction.keypoints[i];\n\n          // Draw keypoint\n          ctx.beginPath();\n          ctx.arc(keypoint.x, keypoint.y, 1, 0, 2 * Math.PI);\n          ctx.fillStyle = 'aqua';\n          ctx.fill();\n        }\n      }\n\n      // Find nose point\n      const nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\n      if (nose) {\n        // Draw the nose point in a different color\n        ctx.beginPath();\n        ctx.arc(nose.x, nose.y, 5, 0, 2 * Math.PI);\n        ctx.fillStyle = 'green';\n        ctx.fill();\n\n        // Draw a line from the center calibration point to current nose position\n        if (calibrationRef.current) {\n          ctx.beginPath();\n          ctx.moveTo(centerPointRef.current.x, centerPointRef.current.y);\n          ctx.lineTo(nose.x, nose.y);\n          ctx.strokeStyle = 'white';\n          ctx.lineWidth = 2;\n          ctx.stroke();\n\n          // Draw the center calibration point\n          ctx.beginPath();\n          ctx.arc(centerPointRef.current.x, centerPointRef.current.y, 5, 0, 2 * Math.PI);\n          ctx.fillStyle = 'red';\n          ctx.fill();\n        }\n      }\n    });\n  };\n\n  // Detect faces and send head movement\n  const detectFaces = async () => {\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\n      requestRef.current = requestAnimationFrame(detectFaces);\n      return;\n    }\n    try {\n      // Get predictions using the updated API\n      const predictions = await modelRef.current.estimateFaces(videoRef.current, {\n        flipHorizontal: true\n      });\n\n      // Update face detected state\n      setFaceDetected(predictions.length > 0);\n\n      // Draw landmarks if debug is enabled\n      if (showDebug && canvasRef.current) {\n        const ctx = canvasRef.current.getContext('2d');\n        drawFacialLandmarks(predictions, ctx);\n      }\n      if (predictions.length > 0) {\n        // Get nose point (middle of the face)\n        const nose = predictions[0].keypoints.find(kp => kp.name === 'nose_tip');\n        if (nose) {\n          // Store current position\n          lastPositionRef.current = {\n            x: nose.x,\n            y: nose.y\n          };\n\n          // If we haven't calibrated yet, do it now\n          if (!calibrationRef.current) {\n            calibrate();\n            return;\n          }\n\n          // Calculate difference from center (calibrated position)\n          const deltaX = nose.x - centerPointRef.current.x;\n          const deltaY = nose.y - centerPointRef.current.y;\n\n          // Determine thresholds for movement (adjust these values as needed)\n          const thresholdX = 30;\n          const thresholdY = 30;\n\n          // Determine movement direction\n          let direction = null;\n\n          // Check horizontal movement (left/right)\n          if (deltaX < -thresholdX) {\n            direction = 'l'; // Left\n          } else if (deltaX > thresholdX) {\n            direction = 'r'; // Right\n          }\n          // Check vertical movement (up/down) - Y increases downward in image coordinates\n          else if (deltaY < -thresholdY) {\n            direction = 'u'; // Up\n          } else if (deltaY > thresholdY) {\n            direction = 'd'; // Down\n          }\n\n          // Call the callback with the detected direction\n          if (direction && onHeadMovement) {\n            onHeadMovement(direction);\n          }\n        }\n      }\n    } catch (error) {\n      console.error('Error during face detection:', error);\n    }\n\n    // Continue detection loop\n    requestRef.current = requestAnimationFrame(detectFaces);\n  };\n\n  // Initialize camera and model\n  useEffect(() => {\n    if (active) {\n      tf.ready().then(() => {\n        setupCamera().then(() => {\n          loadModel();\n        });\n      });\n    }\n    return () => {\n      // Clean up resources\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n        requestRef.current = null;\n      }\n      if (streamRef.current) {\n        const tracks = streamRef.current.getTracks();\n        tracks.forEach(track => track.stop());\n        streamRef.current = null;\n      }\n    };\n  }, [active]);\n\n  // Start detection when model is loaded\n  useEffect(() => {\n    if (isModelLoaded && active) {\n      detectFaces();\n    }\n    return () => {\n      if (requestRef.current) {\n        cancelAnimationFrame(requestRef.current);\n      }\n    };\n  }, [isModelLoaded, active, showDebug]);\n\n  // Handle video loaded\n  const handleVideoLoaded = () => {\n    console.log('Video element is ready');\n\n    // Set canvas dimensions to match video\n    if (canvasRef.current && videoRef.current) {\n      canvasRef.current.width = videoRef.current.videoWidth;\n      canvasRef.current.height = videoRef.current.videoHeight;\n    }\n  };\n\n  // Reset calibration with a function that can be exposed if needed\n  const resetCalibration = () => {\n    calibrationRef.current = false;\n    console.log('Calibration reset');\n  };\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: `face-detection ${showDebug ? 'debug-mode' : ''}`,\n    children: [/*#__PURE__*/_jsxDEV(\"video\", {\n      ref: videoRef,\n      width: \"320\",\n      height: \"240\",\n      autoPlay: true,\n      playsInline: true,\n      muted: true,\n      onLoadedData: handleVideoLoaded,\n      style: {\n        display: showDebug ? 'block' : 'none'\n      },\n      className: \"face-video\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 261,\n      columnNumber: 7\n    }, this), showDebug && /*#__PURE__*/_jsxDEV(\"canvas\", {\n      ref: canvasRef,\n      width: \"320\",\n      height: \"240\",\n      className: \"landmarks-canvas\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 274,\n      columnNumber: 9\n    }, this), !isModelLoaded && active && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"loading-model\",\n      children: \"Loading face detection model...\"\n    }, void 0, false, {\n      fileName: _jsxFileName,\n      lineNumber: 283,\n      columnNumber: 9\n    }, this), faceDetected && active && !showDebug && /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"face-detection-status\",\n      children: [\"Face \", calibrationRef.current ? 'Tracked' : 'Detected']\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 287,\n      columnNumber: 9\n    }, this)]\n  }, void 0, true, {\n    fileName: _jsxFileName,\n    lineNumber: 260,\n    columnNumber: 5\n  }, this);\n}, \"qWFLgGl2VifbDxvDsfBbJhvelBw=\")), \"qWFLgGl2VifbDxvDsfBbJhvelBw=\");\n_c2 = FaceDetection;\nexport default FaceDetection;\nvar _c, _c2;\n$RefreshReg$(_c, \"FaceDetection$forwardRef\");\n$RefreshReg$(_c2, \"FaceDetection\");","map":{"version":3,"names":["React","useEffect","useRef","useState","useImperativeHandle","forwardRef","tf","faceLandmarksDetection","jsxDEV","_jsxDEV","FaceDetection","_s","_c","onHeadMovement","active","showDebug","ref","videoRef","canvasRef","streamRef","modelRef","requestRef","isModelLoaded","setIsModelLoaded","lastPositionRef","x","y","centerPointRef","calibrationRef","faceDetected","setFaceDetected","calibrate","isCalibrated","current","isFaceDetected","loadModel","createDetector","SupportedModels","MediaPipeFaceMesh","runtime","refineLandmarks","maxFaces","console","log","error","setupCamera","navigator","mediaDevices","getUserMedia","video","width","height","facingMode","srcObject","drawFacialLandmarks","predictions","ctx","length","clearRect","canvas","forEach","prediction","keypoints","i","keypoint","beginPath","arc","Math","PI","fillStyle","fill","nose","find","kp","name","moveTo","lineTo","strokeStyle","lineWidth","stroke","detectFaces","readyState","requestAnimationFrame","estimateFaces","flipHorizontal","getContext","deltaX","deltaY","thresholdX","thresholdY","direction","ready","then","cancelAnimationFrame","tracks","getTracks","track","stop","handleVideoLoaded","videoWidth","videoHeight","resetCalibration","className","children","autoPlay","playsInline","muted","onLoadedData","style","display","fileName","_jsxFileName","lineNumber","columnNumber","_c2","$RefreshReg$"],"sources":["C:/Users/kheri/Downloads/Bitcamp/bitcamp-2025/Bitcamp25/test-voice/src/FaceDetection.js"],"sourcesContent":["import React, { useEffect, useRef, useState, useImperativeHandle, forwardRef } from 'react';\r\nimport * as tf from '@tensorflow/tfjs';\r\nimport * as faceLandmarksDetection from '@tensorflow-models/face-landmarks-detection';\r\n\r\nconst FaceDetection = forwardRef(({ onHeadMovement, active = true, showDebug = false }, ref) => {\r\n  const videoRef = useRef(null);\r\n  const canvasRef = useRef(null);\r\n  const streamRef = useRef(null);\r\n  const modelRef = useRef(null);\r\n  const requestRef = useRef(null);\r\n  const [isModelLoaded, setIsModelLoaded] = useState(false);\r\n  const lastPositionRef = useRef({ x: 0, y: 0 });\r\n  const centerPointRef = useRef({ x: 0, y: 0 });\r\n  const calibrationRef = useRef(false);\r\n  const [faceDetected, setFaceDetected] = useState(false);\r\n  \r\n  // Expose functions to parent component\r\n  useImperativeHandle(ref, () => ({\r\n    calibrate: () => {\r\n      calibrate();\r\n    },\r\n    isCalibrated: () => {\r\n      return calibrationRef.current;\r\n    },\r\n    isFaceDetected: () => {\r\n      return faceDetected;\r\n    }\r\n  }));\r\n  \r\n  // Load face detection model\r\n  const loadModel = async () => {\r\n    try {\r\n      // Load the MediaPipe Facemesh package using the current API\r\n      modelRef.current = await faceLandmarksDetection.createDetector(\r\n        faceLandmarksDetection.SupportedModels.MediaPipeFaceMesh,\r\n        {\r\n          runtime: 'mediapipe',\r\n          refineLandmarks: false,\r\n          maxFaces: 1\r\n        }\r\n      );\r\n      setIsModelLoaded(true);\r\n      console.log('Face detection model loaded');\r\n    } catch (error) {\r\n      console.error('Failed to load face detection model:', error);\r\n    }\r\n  };\r\n\r\n  // Set up webcam streaming\r\n  const setupCamera = async () => {\r\n    if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {\r\n      console.error('Browser API navigator.mediaDevices.getUserMedia not available');\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get access to the webcam\r\n      streamRef.current = await navigator.mediaDevices.getUserMedia({\r\n        video: { width: 640, height: 480, facingMode: 'user' }\r\n      });\r\n\r\n      // Set the video source\r\n      if (videoRef.current) {\r\n        videoRef.current.srcObject = streamRef.current;\r\n      }\r\n    } catch (error) {\r\n      console.error('Failed to access webcam:', error);\r\n    }\r\n  };\r\n\r\n  const calibrate = () => {\r\n    if (lastPositionRef.current) {\r\n      centerPointRef.current = { ...lastPositionRef.current };\r\n      calibrationRef.current = true;\r\n      console.log('Calibrated face position:', centerPointRef.current);\r\n    }\r\n  };\r\n\r\n  // Draw facial landmarks for debugging\r\n  const drawFacialLandmarks = (predictions, ctx) => {\r\n    if (!ctx || !predictions || predictions.length === 0) return;\r\n    \r\n    // Clear the canvas\r\n    ctx.clearRect(0, 0, ctx.canvas.width, ctx.canvas.height);\r\n    \r\n    // Draw each prediction\r\n    predictions.forEach(prediction => {\r\n      // Draw facial keypoints\r\n      if (prediction.keypoints) {\r\n        for (let i = 0; i < prediction.keypoints.length; i++) {\r\n          const keypoint = prediction.keypoints[i];\r\n          \r\n          // Draw keypoint\r\n          ctx.beginPath();\r\n          ctx.arc(keypoint.x, keypoint.y, 1, 0, 2 * Math.PI);\r\n          ctx.fillStyle = 'aqua';\r\n          ctx.fill();\r\n        }\r\n      }\r\n      \r\n      // Find nose point\r\n      const nose = prediction.keypoints.find(kp => kp.name === 'nose_tip');\r\n      \r\n      if (nose) {\r\n        // Draw the nose point in a different color\r\n        ctx.beginPath();\r\n        ctx.arc(nose.x, nose.y, 5, 0, 2 * Math.PI);\r\n        ctx.fillStyle = 'green';\r\n        ctx.fill();\r\n        \r\n        // Draw a line from the center calibration point to current nose position\r\n        if (calibrationRef.current) {\r\n          ctx.beginPath();\r\n          ctx.moveTo(centerPointRef.current.x, centerPointRef.current.y);\r\n          ctx.lineTo(nose.x, nose.y);\r\n          ctx.strokeStyle = 'white';\r\n          ctx.lineWidth = 2;\r\n          ctx.stroke();\r\n          \r\n          // Draw the center calibration point\r\n          ctx.beginPath();\r\n          ctx.arc(centerPointRef.current.x, centerPointRef.current.y, 5, 0, 2 * Math.PI);\r\n          ctx.fillStyle = 'red';\r\n          ctx.fill();\r\n        }\r\n      }\r\n    });\r\n  };\r\n\r\n  // Detect faces and send head movement\r\n  const detectFaces = async () => {\r\n    if (!modelRef.current || !videoRef.current || !videoRef.current.readyState === 4) {\r\n      requestRef.current = requestAnimationFrame(detectFaces);\r\n      return;\r\n    }\r\n\r\n    try {\r\n      // Get predictions using the updated API\r\n      const predictions = await modelRef.current.estimateFaces(videoRef.current, {\r\n        flipHorizontal: true\r\n      });\r\n\r\n      // Update face detected state\r\n      setFaceDetected(predictions.length > 0);\r\n      \r\n      // Draw landmarks if debug is enabled\r\n      if (showDebug && canvasRef.current) {\r\n        const ctx = canvasRef.current.getContext('2d');\r\n        drawFacialLandmarks(predictions, ctx);\r\n      }\r\n\r\n      if (predictions.length > 0) {\r\n        // Get nose point (middle of the face)\r\n        const nose = predictions[0].keypoints.find(kp => kp.name === 'nose_tip');\r\n        \r\n        if (nose) {\r\n          // Store current position\r\n          lastPositionRef.current = { x: nose.x, y: nose.y };\r\n          \r\n          // If we haven't calibrated yet, do it now\r\n          if (!calibrationRef.current) {\r\n            calibrate();\r\n            return;\r\n          }\r\n          \r\n          // Calculate difference from center (calibrated position)\r\n          const deltaX = nose.x - centerPointRef.current.x;\r\n          const deltaY = nose.y - centerPointRef.current.y;\r\n          \r\n          // Determine thresholds for movement (adjust these values as needed)\r\n          const thresholdX = 30;\r\n          const thresholdY = 30;\r\n          \r\n          // Determine movement direction\r\n          let direction = null;\r\n          \r\n          // Check horizontal movement (left/right)\r\n          if (deltaX < -thresholdX) {\r\n            direction = 'l'; // Left\r\n          } else if (deltaX > thresholdX) {\r\n            direction = 'r'; // Right\r\n          }\r\n          // Check vertical movement (up/down) - Y increases downward in image coordinates\r\n          else if (deltaY < -thresholdY) {\r\n            direction = 'u'; // Up\r\n          } else if (deltaY > thresholdY) {\r\n            direction = 'd'; // Down\r\n          }\r\n          \r\n          // Call the callback with the detected direction\r\n          if (direction && onHeadMovement) {\r\n            onHeadMovement(direction);\r\n          }\r\n        }\r\n      }\r\n    } catch (error) {\r\n      console.error('Error during face detection:', error);\r\n    }\r\n    \r\n    // Continue detection loop\r\n    requestRef.current = requestAnimationFrame(detectFaces);\r\n  };\r\n\r\n  // Initialize camera and model\r\n  useEffect(() => {\r\n    if (active) {\r\n      tf.ready().then(() => {\r\n        setupCamera().then(() => {\r\n          loadModel();\r\n        });\r\n      });\r\n    }\r\n\r\n    return () => {\r\n      // Clean up resources\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n        requestRef.current = null;\r\n      }\r\n      \r\n      if (streamRef.current) {\r\n        const tracks = streamRef.current.getTracks();\r\n        tracks.forEach(track => track.stop());\r\n        streamRef.current = null;\r\n      }\r\n    };\r\n  }, [active]);\r\n\r\n  // Start detection when model is loaded\r\n  useEffect(() => {\r\n    if (isModelLoaded && active) {\r\n      detectFaces();\r\n    }\r\n    \r\n    return () => {\r\n      if (requestRef.current) {\r\n        cancelAnimationFrame(requestRef.current);\r\n      }\r\n    };\r\n  }, [isModelLoaded, active, showDebug]);\r\n\r\n  // Handle video loaded\r\n  const handleVideoLoaded = () => {\r\n    console.log('Video element is ready');\r\n    \r\n    // Set canvas dimensions to match video\r\n    if (canvasRef.current && videoRef.current) {\r\n      canvasRef.current.width = videoRef.current.videoWidth;\r\n      canvasRef.current.height = videoRef.current.videoHeight;\r\n    }\r\n  };\r\n\r\n  // Reset calibration with a function that can be exposed if needed\r\n  const resetCalibration = () => {\r\n    calibrationRef.current = false;\r\n    console.log('Calibration reset');\r\n  };\r\n\r\n  return (\r\n    <div className={`face-detection ${showDebug ? 'debug-mode' : ''}`}>\r\n      <video \r\n        ref={videoRef}\r\n        width=\"320\"\r\n        height=\"240\"\r\n        autoPlay\r\n        playsInline\r\n        muted\r\n        onLoadedData={handleVideoLoaded}\r\n        style={{ display: showDebug ? 'block' : 'none' }}\r\n        className=\"face-video\"\r\n      />\r\n      \r\n      {showDebug && (\r\n        <canvas \r\n          ref={canvasRef}\r\n          width=\"320\"\r\n          height=\"240\"\r\n          className=\"landmarks-canvas\"\r\n        />\r\n      )}\r\n      \r\n      {!isModelLoaded && active && (\r\n        <div className=\"loading-model\">Loading face detection model...</div>\r\n      )}\r\n      \r\n      {faceDetected && active && !showDebug && (\r\n        <div className=\"face-detection-status\">\r\n          Face {calibrationRef.current ? 'Tracked' : 'Detected'}\r\n        </div>\r\n      )}\r\n    </div>\r\n  );\r\n});\r\n\r\nexport default FaceDetection; "],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,SAAS,EAAEC,MAAM,EAAEC,QAAQ,EAAEC,mBAAmB,EAAEC,UAAU,QAAQ,OAAO;AAC3F,OAAO,KAAKC,EAAE,MAAM,kBAAkB;AACtC,OAAO,KAAKC,sBAAsB,MAAM,6CAA6C;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEtF,MAAMC,aAAa,gBAAAC,EAAA,cAAGN,UAAU,CAAAO,EAAA,GAAAD,EAAA,CAAC,CAAC;EAAEE,cAAc;EAAEC,MAAM,GAAG,IAAI;EAAEC,SAAS,GAAG;AAAM,CAAC,EAAEC,GAAG,KAAK;EAAAL,EAAA;EAC9F,MAAMM,QAAQ,GAAGf,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMgB,SAAS,GAAGhB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMiB,SAAS,GAAGjB,MAAM,CAAC,IAAI,CAAC;EAC9B,MAAMkB,QAAQ,GAAGlB,MAAM,CAAC,IAAI,CAAC;EAC7B,MAAMmB,UAAU,GAAGnB,MAAM,CAAC,IAAI,CAAC;EAC/B,MAAM,CAACoB,aAAa,EAAEC,gBAAgB,CAAC,GAAGpB,QAAQ,CAAC,KAAK,CAAC;EACzD,MAAMqB,eAAe,GAAGtB,MAAM,CAAC;IAAEuB,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC9C,MAAMC,cAAc,GAAGzB,MAAM,CAAC;IAAEuB,CAAC,EAAE,CAAC;IAAEC,CAAC,EAAE;EAAE,CAAC,CAAC;EAC7C,MAAME,cAAc,GAAG1B,MAAM,CAAC,KAAK,CAAC;EACpC,MAAM,CAAC2B,YAAY,EAAEC,eAAe,CAAC,GAAG3B,QAAQ,CAAC,KAAK,CAAC;;EAEvD;EACAC,mBAAmB,CAACY,GAAG,EAAE,OAAO;IAC9Be,SAAS,EAAEA,CAAA,KAAM;MACfA,SAAS,CAAC,CAAC;IACb,CAAC;IACDC,YAAY,EAAEA,CAAA,KAAM;MAClB,OAAOJ,cAAc,CAACK,OAAO;IAC/B,CAAC;IACDC,cAAc,EAAEA,CAAA,KAAM;MACpB,OAAOL,YAAY;IACrB;EACF,CAAC,CAAC,CAAC;;EAEH;EACA,MAAMM,SAAS,GAAG,MAAAA,CAAA,KAAY;IAC5B,IAAI;MACF;MACAf,QAAQ,CAACa,OAAO,GAAG,MAAM1B,sBAAsB,CAAC6B,cAAc,CAC5D7B,sBAAsB,CAAC8B,eAAe,CAACC,iBAAiB,EACxD;QACEC,OAAO,EAAE,WAAW;QACpBC,eAAe,EAAE,KAAK;QACtBC,QAAQ,EAAE;MACZ,CACF,CAAC;MACDlB,gBAAgB,CAAC,IAAI,CAAC;MACtBmB,OAAO,CAACC,GAAG,CAAC,6BAA6B,CAAC;IAC5C,CAAC,CAAC,OAAOC,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,sCAAsC,EAAEA,KAAK,CAAC;IAC9D;EACF,CAAC;;EAED;EACA,MAAMC,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAACC,SAAS,CAACC,YAAY,IAAI,CAACD,SAAS,CAACC,YAAY,CAACC,YAAY,EAAE;MACnEN,OAAO,CAACE,KAAK,CAAC,+DAA+D,CAAC;MAC9E;IACF;IAEA,IAAI;MACF;MACAzB,SAAS,CAACc,OAAO,GAAG,MAAMa,SAAS,CAACC,YAAY,CAACC,YAAY,CAAC;QAC5DC,KAAK,EAAE;UAAEC,KAAK,EAAE,GAAG;UAAEC,MAAM,EAAE,GAAG;UAAEC,UAAU,EAAE;QAAO;MACvD,CAAC,CAAC;;MAEF;MACA,IAAInC,QAAQ,CAACgB,OAAO,EAAE;QACpBhB,QAAQ,CAACgB,OAAO,CAACoB,SAAS,GAAGlC,SAAS,CAACc,OAAO;MAChD;IACF,CAAC,CAAC,OAAOW,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,0BAA0B,EAAEA,KAAK,CAAC;IAClD;EACF,CAAC;EAED,MAAMb,SAAS,GAAGA,CAAA,KAAM;IACtB,IAAIP,eAAe,CAACS,OAAO,EAAE;MAC3BN,cAAc,CAACM,OAAO,GAAG;QAAE,GAAGT,eAAe,CAACS;MAAQ,CAAC;MACvDL,cAAc,CAACK,OAAO,GAAG,IAAI;MAC7BS,OAAO,CAACC,GAAG,CAAC,2BAA2B,EAAEhB,cAAc,CAACM,OAAO,CAAC;IAClE;EACF,CAAC;;EAED;EACA,MAAMqB,mBAAmB,GAAGA,CAACC,WAAW,EAAEC,GAAG,KAAK;IAChD,IAAI,CAACA,GAAG,IAAI,CAACD,WAAW,IAAIA,WAAW,CAACE,MAAM,KAAK,CAAC,EAAE;;IAEtD;IACAD,GAAG,CAACE,SAAS,CAAC,CAAC,EAAE,CAAC,EAAEF,GAAG,CAACG,MAAM,CAACT,KAAK,EAAEM,GAAG,CAACG,MAAM,CAACR,MAAM,CAAC;;IAExD;IACAI,WAAW,CAACK,OAAO,CAACC,UAAU,IAAI;MAChC;MACA,IAAIA,UAAU,CAACC,SAAS,EAAE;QACxB,KAAK,IAAIC,CAAC,GAAG,CAAC,EAAEA,CAAC,GAAGF,UAAU,CAACC,SAAS,CAACL,MAAM,EAAEM,CAAC,EAAE,EAAE;UACpD,MAAMC,QAAQ,GAAGH,UAAU,CAACC,SAAS,CAACC,CAAC,CAAC;;UAExC;UACAP,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACU,GAAG,CAACF,QAAQ,CAACvC,CAAC,EAAEuC,QAAQ,CAACtC,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGyC,IAAI,CAACC,EAAE,CAAC;UAClDZ,GAAG,CAACa,SAAS,GAAG,MAAM;UACtBb,GAAG,CAACc,IAAI,CAAC,CAAC;QACZ;MACF;;MAEA;MACA,MAAMC,IAAI,GAAGV,UAAU,CAACC,SAAS,CAACU,IAAI,CAACC,EAAE,IAAIA,EAAE,CAACC,IAAI,KAAK,UAAU,CAAC;MAEpE,IAAIH,IAAI,EAAE;QACR;QACAf,GAAG,CAACS,SAAS,CAAC,CAAC;QACfT,GAAG,CAACU,GAAG,CAACK,IAAI,CAAC9C,CAAC,EAAE8C,IAAI,CAAC7C,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGyC,IAAI,CAACC,EAAE,CAAC;QAC1CZ,GAAG,CAACa,SAAS,GAAG,OAAO;QACvBb,GAAG,CAACc,IAAI,CAAC,CAAC;;QAEV;QACA,IAAI1C,cAAc,CAACK,OAAO,EAAE;UAC1BuB,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACmB,MAAM,CAAChD,cAAc,CAACM,OAAO,CAACR,CAAC,EAAEE,cAAc,CAACM,OAAO,CAACP,CAAC,CAAC;UAC9D8B,GAAG,CAACoB,MAAM,CAACL,IAAI,CAAC9C,CAAC,EAAE8C,IAAI,CAAC7C,CAAC,CAAC;UAC1B8B,GAAG,CAACqB,WAAW,GAAG,OAAO;UACzBrB,GAAG,CAACsB,SAAS,GAAG,CAAC;UACjBtB,GAAG,CAACuB,MAAM,CAAC,CAAC;;UAEZ;UACAvB,GAAG,CAACS,SAAS,CAAC,CAAC;UACfT,GAAG,CAACU,GAAG,CAACvC,cAAc,CAACM,OAAO,CAACR,CAAC,EAAEE,cAAc,CAACM,OAAO,CAACP,CAAC,EAAE,CAAC,EAAE,CAAC,EAAE,CAAC,GAAGyC,IAAI,CAACC,EAAE,CAAC;UAC9EZ,GAAG,CAACa,SAAS,GAAG,KAAK;UACrBb,GAAG,CAACc,IAAI,CAAC,CAAC;QACZ;MACF;IACF,CAAC,CAAC;EACJ,CAAC;;EAED;EACA,MAAMU,WAAW,GAAG,MAAAA,CAAA,KAAY;IAC9B,IAAI,CAAC5D,QAAQ,CAACa,OAAO,IAAI,CAAChB,QAAQ,CAACgB,OAAO,IAAI,CAAChB,QAAQ,CAACgB,OAAO,CAACgD,UAAU,KAAK,CAAC,EAAE;MAChF5D,UAAU,CAACY,OAAO,GAAGiD,qBAAqB,CAACF,WAAW,CAAC;MACvD;IACF;IAEA,IAAI;MACF;MACA,MAAMzB,WAAW,GAAG,MAAMnC,QAAQ,CAACa,OAAO,CAACkD,aAAa,CAAClE,QAAQ,CAACgB,OAAO,EAAE;QACzEmD,cAAc,EAAE;MAClB,CAAC,CAAC;;MAEF;MACAtD,eAAe,CAACyB,WAAW,CAACE,MAAM,GAAG,CAAC,CAAC;;MAEvC;MACA,IAAI1C,SAAS,IAAIG,SAAS,CAACe,OAAO,EAAE;QAClC,MAAMuB,GAAG,GAAGtC,SAAS,CAACe,OAAO,CAACoD,UAAU,CAAC,IAAI,CAAC;QAC9C/B,mBAAmB,CAACC,WAAW,EAAEC,GAAG,CAAC;MACvC;MAEA,IAAID,WAAW,CAACE,MAAM,GAAG,CAAC,EAAE;QAC1B;QACA,MAAMc,IAAI,GAAGhB,WAAW,CAAC,CAAC,CAAC,CAACO,SAAS,CAACU,IAAI,CAACC,EAAE,IAAIA,EAAE,CAACC,IAAI,KAAK,UAAU,CAAC;QAExE,IAAIH,IAAI,EAAE;UACR;UACA/C,eAAe,CAACS,OAAO,GAAG;YAAER,CAAC,EAAE8C,IAAI,CAAC9C,CAAC;YAAEC,CAAC,EAAE6C,IAAI,CAAC7C;UAAE,CAAC;;UAElD;UACA,IAAI,CAACE,cAAc,CAACK,OAAO,EAAE;YAC3BF,SAAS,CAAC,CAAC;YACX;UACF;;UAEA;UACA,MAAMuD,MAAM,GAAGf,IAAI,CAAC9C,CAAC,GAAGE,cAAc,CAACM,OAAO,CAACR,CAAC;UAChD,MAAM8D,MAAM,GAAGhB,IAAI,CAAC7C,CAAC,GAAGC,cAAc,CAACM,OAAO,CAACP,CAAC;;UAEhD;UACA,MAAM8D,UAAU,GAAG,EAAE;UACrB,MAAMC,UAAU,GAAG,EAAE;;UAErB;UACA,IAAIC,SAAS,GAAG,IAAI;;UAEpB;UACA,IAAIJ,MAAM,GAAG,CAACE,UAAU,EAAE;YACxBE,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB,CAAC,MAAM,IAAIJ,MAAM,GAAGE,UAAU,EAAE;YAC9BE,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB;UACA;UAAA,KACK,IAAIH,MAAM,GAAG,CAACE,UAAU,EAAE;YAC7BC,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB,CAAC,MAAM,IAAIH,MAAM,GAAGE,UAAU,EAAE;YAC9BC,SAAS,GAAG,GAAG,CAAC,CAAC;UACnB;;UAEA;UACA,IAAIA,SAAS,IAAI7E,cAAc,EAAE;YAC/BA,cAAc,CAAC6E,SAAS,CAAC;UAC3B;QACF;MACF;IACF,CAAC,CAAC,OAAO9C,KAAK,EAAE;MACdF,OAAO,CAACE,KAAK,CAAC,8BAA8B,EAAEA,KAAK,CAAC;IACtD;;IAEA;IACAvB,UAAU,CAACY,OAAO,GAAGiD,qBAAqB,CAACF,WAAW,CAAC;EACzD,CAAC;;EAED;EACA/E,SAAS,CAAC,MAAM;IACd,IAAIa,MAAM,EAAE;MACVR,EAAE,CAACqF,KAAK,CAAC,CAAC,CAACC,IAAI,CAAC,MAAM;QACpB/C,WAAW,CAAC,CAAC,CAAC+C,IAAI,CAAC,MAAM;UACvBzD,SAAS,CAAC,CAAC;QACb,CAAC,CAAC;MACJ,CAAC,CAAC;IACJ;IAEA,OAAO,MAAM;MACX;MACA,IAAId,UAAU,CAACY,OAAO,EAAE;QACtB4D,oBAAoB,CAACxE,UAAU,CAACY,OAAO,CAAC;QACxCZ,UAAU,CAACY,OAAO,GAAG,IAAI;MAC3B;MAEA,IAAId,SAAS,CAACc,OAAO,EAAE;QACrB,MAAM6D,MAAM,GAAG3E,SAAS,CAACc,OAAO,CAAC8D,SAAS,CAAC,CAAC;QAC5CD,MAAM,CAAClC,OAAO,CAACoC,KAAK,IAAIA,KAAK,CAACC,IAAI,CAAC,CAAC,CAAC;QACrC9E,SAAS,CAACc,OAAO,GAAG,IAAI;MAC1B;IACF,CAAC;EACH,CAAC,EAAE,CAACnB,MAAM,CAAC,CAAC;;EAEZ;EACAb,SAAS,CAAC,MAAM;IACd,IAAIqB,aAAa,IAAIR,MAAM,EAAE;MAC3BkE,WAAW,CAAC,CAAC;IACf;IAEA,OAAO,MAAM;MACX,IAAI3D,UAAU,CAACY,OAAO,EAAE;QACtB4D,oBAAoB,CAACxE,UAAU,CAACY,OAAO,CAAC;MAC1C;IACF,CAAC;EACH,CAAC,EAAE,CAACX,aAAa,EAAER,MAAM,EAAEC,SAAS,CAAC,CAAC;;EAEtC;EACA,MAAMmF,iBAAiB,GAAGA,CAAA,KAAM;IAC9BxD,OAAO,CAACC,GAAG,CAAC,wBAAwB,CAAC;;IAErC;IACA,IAAIzB,SAAS,CAACe,OAAO,IAAIhB,QAAQ,CAACgB,OAAO,EAAE;MACzCf,SAAS,CAACe,OAAO,CAACiB,KAAK,GAAGjC,QAAQ,CAACgB,OAAO,CAACkE,UAAU;MACrDjF,SAAS,CAACe,OAAO,CAACkB,MAAM,GAAGlC,QAAQ,CAACgB,OAAO,CAACmE,WAAW;IACzD;EACF,CAAC;;EAED;EACA,MAAMC,gBAAgB,GAAGA,CAAA,KAAM;IAC7BzE,cAAc,CAACK,OAAO,GAAG,KAAK;IAC9BS,OAAO,CAACC,GAAG,CAAC,mBAAmB,CAAC;EAClC,CAAC;EAED,oBACElC,OAAA;IAAK6F,SAAS,EAAE,kBAAkBvF,SAAS,GAAG,YAAY,GAAG,EAAE,EAAG;IAAAwF,QAAA,gBAChE9F,OAAA;MACEO,GAAG,EAAEC,QAAS;MACdiC,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZqD,QAAQ;MACRC,WAAW;MACXC,KAAK;MACLC,YAAY,EAAET,iBAAkB;MAChCU,KAAK,EAAE;QAAEC,OAAO,EAAE9F,SAAS,GAAG,OAAO,GAAG;MAAO,CAAE;MACjDuF,SAAS,EAAC;IAAY;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACvB,CAAC,EAEDlG,SAAS,iBACRN,OAAA;MACEO,GAAG,EAAEE,SAAU;MACfgC,KAAK,EAAC,KAAK;MACXC,MAAM,EAAC,KAAK;MACZmD,SAAS,EAAC;IAAkB;MAAAQ,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAC7B,CACF,EAEA,CAAC3F,aAAa,IAAIR,MAAM,iBACvBL,OAAA;MAAK6F,SAAS,EAAC,eAAe;MAAAC,QAAA,EAAC;IAA+B;MAAAO,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAAK,CACpE,EAEApF,YAAY,IAAIf,MAAM,IAAI,CAACC,SAAS,iBACnCN,OAAA;MAAK6F,SAAS,EAAC,uBAAuB;MAAAC,QAAA,GAAC,OAChC,EAAC3E,cAAc,CAACK,OAAO,GAAG,SAAS,GAAG,UAAU;IAAA;MAAA6E,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OAClD,CACN;EAAA;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACE,CAAC;AAEV,CAAC,kCAAC;AAACC,GAAA,GAhSGxG,aAAa;AAkSnB,eAAeA,aAAa;AAAC,IAAAE,EAAA,EAAAsG,GAAA;AAAAC,YAAA,CAAAvG,EAAA;AAAAuG,YAAA,CAAAD,GAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}